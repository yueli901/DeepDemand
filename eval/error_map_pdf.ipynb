{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b430e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: error_analysis\\pdf_error_maps\\errors_north_mae.pdf (n=2531)\n",
      "Saved: error_analysis\\pdf_error_maps\\errors_south_mae.pdf (n=2557)\n",
      "Saved: error_analysis\\pdf_error_maps\\errors_north_geh.pdf (n=2531)\n",
      "Saved: error_analysis\\pdf_error_maps\\errors_south_geh.pdf (n=2557)\n",
      "Saved: error_analysis\\pdf_error_maps\\legend_mae.pdf\n",
      "Saved: error_analysis\\pdf_error_maps\\legend_geh.pdf\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# ============================================================\n",
    "# Signed error maps (PDF):\n",
    "#   4 maps = (North/South) x (MAE, GEH) with signed coloring\n",
    "#   - Color: red = over (pred>gt), blue = under (pred<gt)\n",
    "#   - Magnitude controls alpha (opacity) using percentile cap\n",
    "#   - Basemap: same as before (GBOverview.tif), greyscaled\n",
    "#   - No Train/Test split: merges train + test predictions\n",
    "#   - Legends: 2 standalone PDFs (MAE and GEH)\n",
    "# ============================================================\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from rasterio.windows import from_bounds\n",
    "from rasterio.enums import Resampling\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "# ========================= INPUTS =========================\n",
    "BASEMAP_TIF   = \"../data/basemap/GBOverview.tif\"  # EPSG:27700\n",
    "EDGES_GEOJSON = \"../data/highway_network/uk_driving_edges_simplified.geojson\"\n",
    "\n",
    "TRAIN_JSON   = \"error_analysis/pred_results_train.json\"\n",
    "TEST_JSON    = \"error_analysis/pred_results_test.json\"\n",
    "\n",
    "# England-ish bbox in EPSG:27700\n",
    "ENGLAND_BBOX_27700 = (0, 0, 700000, 700000)\n",
    "\n",
    "OUT_DIR = Path(\"error_analysis/pdf_error_maps\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "OUT_N_MAE = OUT_DIR / \"errors_north_mae.pdf\"\n",
    "OUT_S_MAE = OUT_DIR / \"errors_south_mae.pdf\"\n",
    "OUT_N_GEH = OUT_DIR / \"errors_north_geh.pdf\"\n",
    "OUT_S_GEH = OUT_DIR / \"errors_south_geh.pdf\"\n",
    "\n",
    "LEGEND_MAE = OUT_DIR / \"legend_mae.svg\"\n",
    "LEGEND_GEH = OUT_DIR / \"legend_geh.svg\"\n",
    "\n",
    "# ========================= STYLING =========================\n",
    "FIGSIZE = (10, 10)\n",
    "LINEWIDTH = 3\n",
    "\n",
    "BASEMAP_MAX_PIX = 2000\n",
    "TILES_ALPHA = 0.5\n",
    "\n",
    "# color: red over / blue under\n",
    "COLOR_OVER  = \"#d73027\"\n",
    "COLOR_UNDER = \"#4575b4\"\n",
    "\n",
    "# alpha scaling\n",
    "ALPHA_MIN, ALPHA_MAX = 0.15, 0.95\n",
    "PCTL_CAP = 95  # use 95th percentile as cap\n",
    "\n",
    "# CRS\n",
    "EDGES_ASSUME_CRS_IF_MISSING = \"EPSG:4326\"\n",
    "\n",
    "# ========================= HELPERS =========================\n",
    "def read_basemap_crop_27700(tif_path: str, bbox_27700, max_pix: int):\n",
    "    xmin, ymin, xmax, ymax = bbox_27700\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        if src.crs is None or src.crs.to_epsg() != 27700:\n",
    "            raise ValueError(\"Basemap must have CRS EPSG:27700.\")\n",
    "        win = from_bounds(xmin, ymin, xmax, ymax, transform=src.transform).round_offsets().round_lengths()\n",
    "        win = win.intersection(rasterio.windows.Window(0, 0, src.width, src.height))\n",
    "        scale = max(win.width / max_pix, win.height / max_pix, 1.0)\n",
    "        out_w = int(max(1, win.width / scale))\n",
    "        out_h = int(max(1, win.height / scale))\n",
    "        data = src.read(window=win, out_shape=(src.count, out_h, out_w), resampling=Resampling.bilinear)\n",
    "        img = np.transpose(data, (1, 2, 0))\n",
    "        left, bottom, right, top = rasterio.windows.bounds(win, src.transform)\n",
    "        extent = (left, right, bottom, top)\n",
    "        return img, extent\n",
    "\n",
    "def ensure_27700(gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    if gdf.crs is None:\n",
    "        gdf = gdf.set_crs(EDGES_ASSUME_CRS_IF_MISSING)\n",
    "    if gdf.crs.to_epsg() != 27700:\n",
    "        gdf = gdf.to_crs(27700)\n",
    "    return gdf\n",
    "\n",
    "def _geom_to_segments(geom):\n",
    "    if geom is None or geom.is_empty:\n",
    "        return []\n",
    "    gt = geom.geom_type\n",
    "    if gt == \"LineString\":\n",
    "        return [np.asarray(geom.coords, dtype=float)]\n",
    "    if gt == \"MultiLineString\":\n",
    "        return [np.asarray(g.coords, dtype=float) for g in geom.geoms if (g is not None and not g.is_empty)]\n",
    "    return []\n",
    "\n",
    "def infer_direction(geom):\n",
    "    \"\"\"northbound if start is more south than end (y_start < y_end).\"\"\"\n",
    "    segs = _geom_to_segments(geom)\n",
    "    if not segs:\n",
    "        return None\n",
    "    s = segs[0]\n",
    "    y0 = float(s[0, 1])\n",
    "    y1 = float(s[-1, 1])\n",
    "    return \"north\" if y0 < y1 else \"south\"\n",
    "\n",
    "def parse_edge_id(eid: str):\n",
    "    p = str(eid).split(\"_\")\n",
    "    if len(p) < 3:\n",
    "        raise ValueError(f\"Bad edge_id (expected u_v_key): {eid}\")\n",
    "    return int(p[0]), int(p[1]), int(p[2])\n",
    "\n",
    "def load_preds(json_path):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        rows = json.load(f)\n",
    "    # If duplicates exist, average pred/gt within edge_id (conservative)\n",
    "    dfp = pd.DataFrame([{\n",
    "        \"edge_id\": str(r[\"edge_id\"]),\n",
    "        \"gt\": float(r[\"gt\"]),\n",
    "        \"pred\": float(r[\"pred\"]),\n",
    "    } for r in rows])\n",
    "    dfp = dfp.groupby(\"edge_id\", as_index=False).mean(numeric_only=True)\n",
    "    return dfp\n",
    "\n",
    "def compute_errors(df_pred: pd.DataFrame):\n",
    "    gt = df_pred[\"gt\"].to_numpy(dtype=float)\n",
    "    pred = df_pred[\"pred\"].to_numpy(dtype=float)\n",
    "    err = pred - gt\n",
    "    mae = np.abs(err)\n",
    "    geh = np.sqrt(2.0 * (err ** 2) / np.maximum(pred + gt, 1e-9))\n",
    "    out = df_pred.copy()\n",
    "    out[\"signed_err\"] = err\n",
    "    out[\"mae\"] = mae\n",
    "    out[\"signed_geh\"] = np.sign(err) * geh\n",
    "    out[\"geh\"] = geh\n",
    "    return out\n",
    "\n",
    "def alpha_from_magnitude(mag: np.ndarray, cap: float):\n",
    "    cap = float(max(cap, 1e-12))\n",
    "    a = np.clip(mag / cap, 0.0, 1.0)\n",
    "    return ALPHA_MIN + (ALPHA_MAX - ALPHA_MIN) * a\n",
    "\n",
    "def add_signed_lines(ax, gdf, signed_vals, mags, cap, linewidth):\n",
    "    \"\"\"\n",
    "    Color depends on sign (over/under). Alpha depends on magnitude.\n",
    "    \"\"\"\n",
    "    alphas = alpha_from_magnitude(np.asarray(mags, dtype=float), cap)\n",
    "\n",
    "    segs = []\n",
    "    cols = []\n",
    "    for geom, sgn, a in zip(gdf.geometry.values, signed_vals, alphas):\n",
    "        color = COLOR_OVER if sgn > 0 else COLOR_UNDER\n",
    "        # convert hex to rgb\n",
    "        h = color.lstrip(\"#\")\n",
    "        r = int(h[0:2], 16) / 255.0\n",
    "        g = int(h[2:4], 16) / 255.0\n",
    "        b = int(h[4:6], 16) / 255.0\n",
    "\n",
    "        for s in _geom_to_segments(geom):\n",
    "            if s.shape[0] >= 2:\n",
    "                segs.append(s)\n",
    "                cols.append((r, g, b, float(a)))\n",
    "\n",
    "    if not segs:\n",
    "        return\n",
    "    lc = LineCollection(segs, colors=cols, linewidths=linewidth, capstyle=\"round\", joinstyle=\"round\")\n",
    "    ax.add_collection(lc)\n",
    "\n",
    "def save_standalone_alpha_legend(out_pdf, title, cap_value, over_color=COLOR_OVER, under_color=COLOR_UNDER):\n",
    "    \"\"\"\n",
    "    Legend shows:\n",
    "      - red/blue meaning (over/under)\n",
    "      - alpha meaning in terms of magnitude from 0 to cap_value (95th percentile)\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(4.5, 1.5))\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    ax.text(0.02, 0.92, title, fontsize=12, weight=\"bold\", va=\"top\")\n",
    "\n",
    "    # color meaning\n",
    "    ax.text(0.02, 0.72, \"Sign\", fontsize=10, weight=\"bold\", va=\"top\")\n",
    "    ax.plot([0.05, 0.20], [0.62, 0.62], color=over_color, linewidth=6)\n",
    "    ax.text(0.22, 0.62, \"Overestimation (Pred > GT)\", fontsize=10, va=\"center\")\n",
    "\n",
    "    ax.plot([0.05, 0.20], [0.50, 0.50], color=under_color, linewidth=6)\n",
    "    ax.text(0.22, 0.50, \"Underestimation (Pred < GT)\", fontsize=10, va=\"center\")\n",
    "\n",
    "    # alpha meaning\n",
    "    ax.text(0.02, 0.34, \"Magnitude (opacity)\", fontsize=10, weight=\"bold\", va=\"top\")\n",
    "    # draw a small opacity ramp (use gray)\n",
    "    xs = np.linspace(0.05, 0.55, 6)\n",
    "    mags = np.linspace(0.0, cap_value, 6)\n",
    "    alps = alpha_from_magnitude(mags, cap_value)\n",
    "\n",
    "    for x, a in zip(xs, alps):\n",
    "        ax.plot([x, x + 0.05], [0.18, 0.18], color=\"black\", linewidth=8, alpha=float(a))\n",
    "\n",
    "    ax.text(0.05, 0.08, f\"0\", fontsize=9, ha=\"left\")\n",
    "    ax.text(0.55, 0.08, f\"{cap_value:.3g} (cap, p{PCTL_CAP})\", fontsize=9, ha=\"right\")\n",
    "    ax.text(0.05, 0.25, \"More opaque = larger error\", fontsize=9)\n",
    "\n",
    "    fig.savefig(out_pdf)\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved: {out_pdf}\")\n",
    "\n",
    "# ========================= LOAD + MERGE PREDS (Train+Test) =========================\n",
    "df_train = load_preds(TRAIN_JSON)\n",
    "df_test  = load_preds(TEST_JSON)\n",
    "\n",
    "df_pred = pd.concat([df_train, df_test], axis=0, ignore_index=True)\n",
    "\n",
    "# If the same edge appears in both, average (so we truly \"do not distinguish\")\n",
    "df_pred = df_pred.groupby(\"edge_id\", as_index=False).mean(numeric_only=True)\n",
    "\n",
    "df_err = compute_errors(df_pred)\n",
    "\n",
    "# Parse u/v/key for join\n",
    "uvk = df_err[\"edge_id\"].apply(parse_edge_id)\n",
    "df_err[\"u\"] = uvk.apply(lambda x: x[0])\n",
    "df_err[\"v\"] = uvk.apply(lambda x: x[1])\n",
    "df_err[\"key\"] = uvk.apply(lambda x: x[2])\n",
    "\n",
    "# ========================= LOAD EDGES =========================\n",
    "edges = gpd.read_file(EDGES_GEOJSON)\n",
    "edges = ensure_27700(edges)\n",
    "\n",
    "need = {\"u\", \"v\", \"key\"}\n",
    "if not need.issubset(set(edges.columns)):\n",
    "    cand = None\n",
    "    for c in [\"edge_id\", \"eid\", \"id\", \"osmid\", \"fid\"]:\n",
    "        if c in edges.columns:\n",
    "            cand = c\n",
    "            break\n",
    "    if cand is None:\n",
    "        raise ValueError(\"Edges GeoJSON must contain columns u,v,key OR an edge_id-like column.\")\n",
    "    parsed = edges[cand].astype(str).apply(parse_edge_id)\n",
    "    edges[\"u\"] = parsed.apply(lambda x: x[0])\n",
    "    edges[\"v\"] = parsed.apply(lambda x: x[1])\n",
    "    edges[\"key\"] = parsed.apply(lambda x: x[2])\n",
    "\n",
    "g2 = edges.merge(df_err, on=[\"u\", \"v\", \"key\"], how=\"inner\")\n",
    "if len(g2) == 0:\n",
    "    raise RuntimeError(\"No edges matched between GeoJSON and pred_results_* (check id consistency).\")\n",
    "\n",
    "# Crop to bbox\n",
    "xmin, ymin, xmax, ymax = ENGLAND_BBOX_27700\n",
    "g2 = g2.cx[xmin:xmax, ymin:ymax].copy()\n",
    "\n",
    "# Split direction\n",
    "g2[\"dir\"] = g2.geometry.apply(infer_direction)\n",
    "north = g2[g2[\"dir\"] == \"north\"].copy()\n",
    "south = g2[g2[\"dir\"] == \"south\"].copy()\n",
    "\n",
    "# Basemap (greyscale)\n",
    "basemap_img, basemap_extent = read_basemap_crop_27700(BASEMAP_TIF, ENGLAND_BBOX_27700, BASEMAP_MAX_PIX)\n",
    "if basemap_img.ndim == 3 and basemap_img.shape[2] >= 3:\n",
    "    basemap_img = np.dot(basemap_img[..., :3], [0.299, 0.587, 0.114])\n",
    "\n",
    "# Caps (percentile) for consistent opacity scaling across all 4 maps\n",
    "mae_cap = float(np.percentile(g2[\"mae\"].to_numpy(dtype=float), PCTL_CAP))\n",
    "geh_cap = float(np.percentile(g2[\"geh\"].to_numpy(dtype=float), PCTL_CAP))\n",
    "\n",
    "# ========================= PLOTTING =========================\n",
    "def plot_map(gdf, which_metric, out_pdf, title):\n",
    "    \"\"\"\n",
    "    which_metric: \"mae\" or \"geh\"\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "    ax.imshow(basemap_img, extent=basemap_extent, cmap=\"gray\", vmin=0, vmax=255, alpha=TILES_ALPHA)\n",
    "    ax.set_xlim(basemap_extent[0], basemap_extent[1])\n",
    "    ax.set_ylim(basemap_extent[2], basemap_extent[3])\n",
    "\n",
    "    if which_metric == \"mae\":\n",
    "        signed_vals = gdf[\"signed_err\"].to_numpy(dtype=float)   # sign from pred-gt\n",
    "        mags = gdf[\"mae\"].to_numpy(dtype=float)\n",
    "        cap = mae_cap\n",
    "    elif which_metric == \"geh\":\n",
    "        signed_vals = gdf[\"signed_geh\"].to_numpy(dtype=float)   # signed GEH\n",
    "        mags = gdf[\"geh\"].to_numpy(dtype=float)\n",
    "        cap = geh_cap\n",
    "    else:\n",
    "        raise ValueError(\"which_metric must be 'mae' or 'geh'\")\n",
    "\n",
    "    add_signed_lines(ax, gdf, signed_vals=signed_vals, mags=mags, cap=cap, linewidth=LINEWIDTH)\n",
    "\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_pdf)\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved: {out_pdf} (n={len(gdf)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97e75a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: error_analysis\\pdf_error_maps\\errors_north_mae.pdf (n=2531)\n",
      "Saved: error_analysis\\pdf_error_maps\\errors_south_mae.pdf (n=2557)\n",
      "Saved: error_analysis\\pdf_error_maps\\errors_north_geh.pdf (n=2531)\n",
      "Saved: error_analysis\\pdf_error_maps\\errors_south_geh.pdf (n=2557)\n",
      "Saved: error_analysis\\pdf_error_maps\\legend_mae.svg\n",
      "Saved: error_analysis\\pdf_error_maps\\legend_geh.svg\n"
     ]
    }
   ],
   "source": [
    "# 4 maps\n",
    "plot_map(north, \"mae\", OUT_N_MAE, \"Signed MAE — Northbound edges (red=over, blue=under)\")\n",
    "plot_map(south, \"mae\", OUT_S_MAE, \"Signed MAE — Southbound edges (red=over, blue=under)\")\n",
    "plot_map(north, \"geh\", OUT_N_GEH, \"Signed GEH — Northbound edges (red=over, blue=under)\")\n",
    "plot_map(south, \"geh\", OUT_S_GEH, \"Signed GEH — Southbound edges (red=over, blue=under)\")\n",
    "\n",
    "# 2 standalone legends (no colorbar; alpha legend + sign legend)\n",
    "save_standalone_alpha_legend(LEGEND_MAE, \"Legend: Signed MAE\", mae_cap)\n",
    "save_standalone_alpha_legend(LEGEND_GEH, \"Legend: Signed GEH\", geh_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44db6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
