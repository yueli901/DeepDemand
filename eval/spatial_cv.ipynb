{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e40d9e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     region  best_val_RMSE  best_val_RMSE_eval  best_val_MAE  best_val_MAE_eval  best_val_MGEH  best_val_MGEH_eval  best_val_R2  best_val_R2_eval  n_val_evals\n",
      "0             East Midlands    9807.255859                  35   6966.020996                 35      51.606220                  35     0.650520                35           55\n",
      "1           East of England   10803.422852                  13   7620.530762                 33      55.697933                  33     0.728260                13           53\n",
      "2                    London   13482.264648                  31   9559.274414                 32      61.599014                  32     0.714243                31           52\n",
      "3                North East    7944.389648                  12   6212.567871                 12      55.935581                  12     0.474198                12           32\n",
      "4                North West   12035.644531                  23   8820.658203                 34      58.136616                  34     0.658674                23           54\n",
      "5                South East   11029.455078                  11   8368.140625                 24      57.820438                  24     0.729141                11           44\n",
      "6                South West    9104.548828                  18   7290.414551                 18      61.694195                  18     0.580030                18           38\n",
      "7             West Midlands   10786.467773                   4   8125.119141                  4      57.186520                   4     0.676905                 4           24\n",
      "8  Yorkshire and the Humber    7911.193359                   6   6054.325195                 25      48.166660                  32     0.777125                 6           52\n",
      "\n",
      "Saved: logs\\spatial_cv_region_best_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Summarise *best* validation metrics per spatial-CV region from logs.\n",
    "\n",
    "Assumptions\n",
    "-----------\n",
    "- You have 9 log files:\n",
    "    logs/spatial_cv_1.log ... logs/spatial_cv_9.log\n",
    "- Validation lines look like:\n",
    "    Epoch X Step Y Validation Eval: RMSE: a, MAE: b, MGEH: c, R2: d (optional stage/lr)\n",
    "\n",
    "Output\n",
    "------\n",
    "- Prints a table (one row per region) with:\n",
    "    best_val_RMSE (min), best_val_MAE (min), best_val_MGEH (min), best_val_R2 (max)\n",
    "  plus the eval step index at which each best occurs.\n",
    "- Also saves CSV: logs/spatial_cv_region_best_metrics.csv\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "LOG_DIR = Path(\"logs\")\n",
    "LOG_TEMPLATE = \"spatial_cv_{i}.log\"   # i = 1..9\n",
    "OUT_CSV = LOG_DIR / \"spatial_cv_region_best_metrics.csv\"\n",
    "\n",
    "REGION_CODE_BY_I = {\n",
    "    1: \"E12000001\",\n",
    "    2: \"E12000002\",\n",
    "    3: \"E12000003\",\n",
    "    4: \"E12000004\",\n",
    "    5: \"E12000005\",\n",
    "    6: \"E12000006\",\n",
    "    7: \"E12000007\",\n",
    "    8: \"E12000008\",\n",
    "    9: \"E12000009\",\n",
    "}\n",
    "\n",
    "# Standard ONS English region names for E12000001..E12000009\n",
    "REGION_NAME_BY_CODE = {\n",
    "    \"E12000001\": \"North East\",\n",
    "    \"E12000002\": \"North West\",\n",
    "    \"E12000003\": \"Yorkshire and the Humber\",\n",
    "    \"E12000004\": \"East Midlands\",\n",
    "    \"E12000005\": \"West Midlands\",\n",
    "    \"E12000006\": \"East of England\",\n",
    "    \"E12000007\": \"London\",\n",
    "    \"E12000008\": \"South East\",\n",
    "    \"E12000009\": \"South West\",\n",
    "}\n",
    "\n",
    "# robust float pattern: 1.23, -4., .5, 1e-3, -2.1E+05\n",
    "FLOAT = r\"[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?\"\n",
    "\n",
    "pattern_val = re.compile(\n",
    "    rf\"Epoch\\s+(?P<epoch>\\d+)\\s+Step\\s+(?P<step>\\d+)\\s+Validation\\s+Eval:\\s*\"\n",
    "    rf\"RMSE:\\s*(?P<rmse>{FLOAT}),\\s*MAE:\\s*(?P<mae>{FLOAT}),\\s*MGEH:\\s*(?P<mgeh>{FLOAT}),\\s*R2:\\s*(?P<r2>{FLOAT})\"\n",
    "    rf\"(?:\\s*\\(stage\\s+(?P<stage_cur>\\d+)\\s*/\\s*(?P<stage_total>\\d+)\\s*,\\s*lr\\s*=\\s*(?P<lr>{FLOAT})\\s*\\))?\",\n",
    "    re.IGNORECASE,\n",
    ")\n",
    "\n",
    "def parse_val_records(text: str):\n",
    "    rows = []\n",
    "    v_idx = 0\n",
    "    for m in pattern_val.finditer(text):\n",
    "        v_idx += 1\n",
    "        g = m.groupdict()\n",
    "        rows.append({\n",
    "            \"eval_idx\": v_idx,  # sequential validation-eval counter\n",
    "            \"epoch\": int(g[\"epoch\"]),\n",
    "            \"step\": int(g[\"step\"]),\n",
    "            \"rmse\": float(g[\"rmse\"]),\n",
    "            \"mae\": float(g[\"mae\"]),\n",
    "            \"mgeh\": float(g[\"mgeh\"]),\n",
    "            \"r2\": float(g[\"r2\"]),\n",
    "            \"stage\": int(g[\"stage_cur\"]) if g[\"stage_cur\"] is not None else None,\n",
    "            \"lr\": float(g[\"lr\"]) if g[\"lr\"] is not None else None,\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def best_min(df: pd.DataFrame, col: str):\n",
    "    if df.empty:\n",
    "        return None, None\n",
    "    i = df[col].astype(float).idxmin()\n",
    "    return float(df.loc[i, col]), int(df.loc[i, \"eval_idx\"])\n",
    "\n",
    "def best_max(df: pd.DataFrame, col: str):\n",
    "    if df.empty:\n",
    "        return None, None\n",
    "    i = df[col].astype(float).idxmax()\n",
    "    return float(df.loc[i, col]), int(df.loc[i, \"eval_idx\"])\n",
    "\n",
    "summaries = []\n",
    "\n",
    "for i in range(1, 10):\n",
    "    code = REGION_CODE_BY_I[i]\n",
    "    region = REGION_NAME_BY_CODE.get(code, code)\n",
    "    log_path = LOG_DIR / LOG_TEMPLATE.format(i=i)\n",
    "    if not log_path.exists():\n",
    "        print(f\"[WARN] Missing log: {log_path}\")\n",
    "        summaries.append({\n",
    "            \"region\": region,\n",
    "            \"best_val_RMSE\": None, \"best_val_RMSE_eval\": None,\n",
    "            \"best_val_MAE\": None,  \"best_val_MAE_eval\": None,\n",
    "            \"best_val_MGEH\": None, \"best_val_MGEH_eval\": None,\n",
    "            \"best_val_R2\": None,   \"best_val_R2_eval\": None,\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    text = log_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    dfv = parse_val_records(text)\n",
    "\n",
    "    rmse_best, rmse_at = best_min(dfv, \"rmse\")\n",
    "    mae_best,  mae_at  = best_min(dfv, \"mae\")\n",
    "    mgeh_best, mgeh_at = best_min(dfv, \"mgeh\")\n",
    "    r2_best,   r2_at   = best_max(dfv, \"r2\")\n",
    "\n",
    "    summaries.append({\n",
    "        \"region\": region,\n",
    "        \"best_val_RMSE\": rmse_best, \"best_val_RMSE_eval\": rmse_at,\n",
    "        \"best_val_MAE\": mae_best,   \"best_val_MAE_eval\": mae_at,\n",
    "        \"best_val_MGEH\": mgeh_best, \"best_val_MGEH_eval\": mgeh_at,\n",
    "        \"best_val_R2\": r2_best,     \"best_val_R2_eval\": r2_at,\n",
    "        \"n_val_evals\": int(dfv.shape[0]),\n",
    "    })\n",
    "\n",
    "out = pd.DataFrame(summaries).sort_values(\"region\").reset_index(drop=True)\n",
    "\n",
    "# pretty print\n",
    "with pd.option_context(\"display.max_columns\", 200, \"display.width\", 200):\n",
    "    print(out)\n",
    "\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "out.to_csv(OUT_CSV, index=False)\n",
    "print(f\"\\nSaved: {OUT_CSV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55561c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      " - figures\\spatial_cv_mgeh_legend.svg\n",
      " - figures\\spatial_cv_mgeh_region_map.pdf\n",
      " - figures\\spatial_cv_mgeh_region_bar.svg\n",
      "                     Region  best_val_MGEH  best_val_MAE  best_val_RMSE  \\\n",
      "0                North East      55.935581   6212.567871    7944.389648   \n",
      "1                North West      58.136616   8820.658203   12115.383789   \n",
      "2  Yorkshire and The Humber      48.166660   6091.789551    8075.288574   \n",
      "3             East Midlands      51.606220   6966.020996    9807.255859   \n",
      "4             West Midlands      57.186520   8125.119141   10786.467773   \n",
      "5           East of England      55.697933   7620.530762   10865.658203   \n",
      "6                    London      61.599014   9559.274414   13509.865234   \n",
      "7                South East      57.820438   8368.140625   11110.619141   \n",
      "8                South West      61.694195   7290.414551    9104.548828   \n",
      "\n",
      "   best_val_R2  \n",
      "0     0.474198  \n",
      "1     0.654137  \n",
      "2     0.767783  \n",
      "3     0.650520  \n",
      "4     0.676905  \n",
      "5     0.725120  \n",
      "6     0.713072  \n",
      "7     0.717855  \n",
      "8     0.580030  \n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# =========================\n",
    "# Inputs\n",
    "# =========================\n",
    "SHP = Path(r\"../data/node_features/boundaries/Regions_December_2022_Boundaries_EN_BFC_V2/RGN_DEC_2022_EN_BFC_V2.shp\")\n",
    "LOG_DIR = Path(\"logs\")\n",
    "LOG_TPL = \"spatial_cv_{}.log\"  # 1..9\n",
    "\n",
    "RANDOM_CV_AVG_MGEH = 54.3\n",
    "\n",
    "OUT_DIR = Path(\"figures\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_MAP_PDF   = OUT_DIR / \"spatial_cv_mgeh_region_map.pdf\"\n",
    "OUT_BAR_PDF   = OUT_DIR / \"spatial_cv_mgeh_region_bar.svg\"\n",
    "OUT_LEG_PDF   = OUT_DIR / \"spatial_cv_mgeh_legend.svg\"\n",
    "\n",
    "# =========================\n",
    "# Region mapping (1..9)\n",
    "# =========================\n",
    "REGION_CODES = [\n",
    "    \"E12000001\", \"E12000002\", \"E12000003\", \"E12000004\", \"E12000005\",\n",
    "    \"E12000006\", \"E12000007\", \"E12000008\", \"E12000009\"\n",
    "]\n",
    "REGION_NAMES = {\n",
    "    \"E12000001\": \"North East\",\n",
    "    \"E12000002\": \"North West\",\n",
    "    \"E12000003\": \"Yorkshire and The Humber\",\n",
    "    \"E12000004\": \"East Midlands\",\n",
    "    \"E12000005\": \"West Midlands\",\n",
    "    \"E12000006\": \"East of England\",\n",
    "    \"E12000007\": \"London\",\n",
    "    \"E12000008\": \"South East\",\n",
    "    \"E12000009\": \"South West\",\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# Parse best validation metrics per region\n",
    "# =========================\n",
    "FLOAT = r\"[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?\"\n",
    "pat_val = re.compile(\n",
    "    rf\"Validation\\s+Eval:\\s*RMSE:\\s*(?P<rmse>{FLOAT}),\\s*MAE:\\s*(?P<mae>{FLOAT}),\\s*MGEH:\\s*(?P<mgeh>{FLOAT}),\\s*R2:\\s*(?P<r2>{FLOAT})\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "rows = []\n",
    "for i, code in enumerate(REGION_CODES, start=1):\n",
    "    p = LOG_DIR / LOG_TPL.format(i)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Missing log: {p}\")\n",
    "\n",
    "    txt = p.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    rmse, mae, mgeh, r2 = [], [], [], []\n",
    "\n",
    "    for m in pat_val.finditer(txt):\n",
    "        g = m.groupdict()\n",
    "        rmse.append(float(g[\"rmse\"]))\n",
    "        mae.append(float(g[\"mae\"]))\n",
    "        mgeh.append(float(g[\"mgeh\"]))\n",
    "        r2.append(float(g[\"r2\"]))\n",
    "\n",
    "    if not mgeh:\n",
    "        raise RuntimeError(f\"No Validation Eval lines found in {p}\")\n",
    "\n",
    "    # best = min MGEH\n",
    "    best_idx = int(np.nanargmin(mgeh))\n",
    "    rows.append({\n",
    "        \"RGN_CODE\": code,\n",
    "        \"Region\": REGION_NAMES.get(code, code),\n",
    "        \"best_val_MGEH\": float(mgeh[best_idx]),\n",
    "        \"best_val_MAE\": float(mae[best_idx]),\n",
    "        \"best_val_RMSE\": float(rmse[best_idx]),\n",
    "        \"best_val_R2\": float(r2[best_idx]),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# =========================\n",
    "# Load regions shapefile + join\n",
    "# =========================\n",
    "gdf = gpd.read_file(SHP)\n",
    "\n",
    "# Try to locate region code field\n",
    "code_cols = [c for c in gdf.columns if c.upper().endswith(\"CD\") and \"RGN\" in c.upper()]\n",
    "if not code_cols:\n",
    "    for c in gdf.columns:\n",
    "        if gdf[c].astype(str).str.startswith(\"E1200000\").any():\n",
    "            code_cols = [c]\n",
    "            break\n",
    "if not code_cols:\n",
    "    raise ValueError(\"Could not find a region code column in the shapefile (expected something like RGN22CD).\")\n",
    "\n",
    "code_col = code_cols[0]\n",
    "gdf[code_col] = gdf[code_col].astype(str)\n",
    "\n",
    "g = gdf.merge(df, left_on=code_col, right_on=\"RGN_CODE\", how=\"inner\")\n",
    "if g.empty:\n",
    "    raise RuntimeError(\"Join produced 0 rows. Check region code column and mappings.\")\n",
    "\n",
    "# =========================\n",
    "# Discrete bins + palette\n",
    "# =========================\n",
    "# bins: 0-50, 50-52, 52-56, 56-58, 58-59, 59+\n",
    "bounds = [48, 50, 52, 56, 58, 59, 62]  # last is just to cap display\n",
    "colors = [\"#ffffb2\", \"#fed976\", \"#feb24c\", \"#fd8d3c\", \"#f03b20\", \"#bd0026\"]\n",
    "\n",
    "cmap = ListedColormap(colors, name=\"mgeh_bins\")\n",
    "norm = BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "def mgeh_bin_labels():\n",
    "    return [\"0–50\", \"50–52\", \"52–56\", \"56–58\", \"58–59\", \"59+\"]\n",
    "\n",
    "def color_for_value(v):\n",
    "    idx = np.digitize([v], bounds)[0] - 1\n",
    "    idx = max(0, min(idx, len(colors) - 1))\n",
    "    return colors[idx]\n",
    "\n",
    "# =========================\n",
    "# (A) Save legend-only PDF\n",
    "# =========================\n",
    "fig = plt.figure(figsize=(0.5, 3))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(bounds[0], bounds[-2])\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "# stacked rectangles\n",
    "for (y0, y1, col) in zip(bounds[:-2], bounds[1:-1], colors[:-1]):\n",
    "    ax.add_patch(mpatches.Rectangle((0.20, y0), 0.38, y1 - y0, facecolor=col, edgecolor=\"none\"))\n",
    "# last bin (59+)\n",
    "ax.add_patch(mpatches.Rectangle((0.20, 59), 0.38, (bounds[-2] - 59), facecolor=colors[-1], edgecolor=\"none\"))\n",
    "\n",
    "# labels\n",
    "# labels = mgeh_bin_labels()\n",
    "# y_mids = [(bounds[i] + bounds[i+1]) / 2 for i in range(len(bounds)-2)]\n",
    "# y_mids[-1] = (59 + bounds[-2]) / 2\n",
    "# for lab, ym in zip(labels, y_mids):\n",
    "#     ax.text(0.62, ym, lab, va=\"center\", ha=\"left\", fontsize=8)\n",
    "\n",
    "# reference line\n",
    "ax.axhline(RANDOM_CV_AVG_MGEH, color=\"gray\", lw=1.0)\n",
    "# ax.text(0.20, RANDOM_CV_AVG_MGEH, \"Random CV avg\", va=\"bottom\", ha=\"left\", fontsize=8, color=\"gray\")\n",
    "\n",
    "for sp in ax.spines.values():\n",
    "    sp.set_visible(False)\n",
    "\n",
    "fig.savefig(OUT_LEG_PDF, bbox_inches=\"tight\", transparent=True)\n",
    "plt.close(fig)\n",
    "\n",
    "# =========================\n",
    "# (B) Save map-only PDF\n",
    "# =========================\n",
    "fig = plt.figure(figsize=(10, 10.0))\n",
    "ax_map = fig.add_subplot(111)\n",
    "\n",
    "g.plot(\n",
    "    ax=ax_map,\n",
    "    column=\"best_val_MGEH\",\n",
    "    cmap=cmap,\n",
    "    norm=norm,\n",
    "    linewidth=0.6,\n",
    "    edgecolor=\"white\",\n",
    ")\n",
    "ax_map.set_axis_off()\n",
    "\n",
    "fig.savefig(OUT_MAP_PDF, bbox_inches=\"tight\", transparent=True)\n",
    "plt.close(fig)\n",
    "\n",
    "# =========================\n",
    "# (C) Save bar-only PDF\n",
    "# =========================\n",
    "df_bar = df.sort_values(\"best_val_MGEH\", ascending=False).reset_index(drop=True)\n",
    "ypos = np.arange(len(df_bar))\n",
    "bar_colors = [color_for_value(v) for v in df_bar[\"best_val_MGEH\"].to_numpy()]\n",
    "\n",
    "fig = plt.figure(figsize=(4.5, 4))\n",
    "ax_bar = fig.add_subplot(111)\n",
    "\n",
    "ax_bar.barh(ypos, df_bar[\"best_val_MGEH\"].to_numpy(), color=bar_colors, edgecolor=\"none\")\n",
    "ax_bar.set_yticks(ypos)\n",
    "ax_bar.set_yticklabels(df_bar[\"Region\"].tolist())\n",
    "ax_bar.invert_yaxis()\n",
    "\n",
    "ax_bar.set_xlim(40, 70)\n",
    "ax_bar.axvline(RANDOM_CV_AVG_MGEH, linestyle=\":\", lw=2, color='gray')\n",
    "\n",
    "# remove top/right spines\n",
    "ax_bar.spines[\"top\"].set_visible(False)\n",
    "ax_bar.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# no title\n",
    "ax_bar.set_xlabel(\"Best test MGEH\")\n",
    "\n",
    "# annotate values\n",
    "for y, v in zip(ypos, df_bar[\"best_val_MGEH\"].to_numpy()):\n",
    "    ax_bar.text(min(v + 0.3, 69.5), y, f\"{v:.1f}\", va=\"center\", ha=\"left\", fontsize=9)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(OUT_BAR_PDF, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" -\", OUT_LEG_PDF)\n",
    "print(\" -\", OUT_MAP_PDF)\n",
    "print(\" -\", OUT_BAR_PDF)\n",
    "print(df[[\"Region\", \"best_val_MGEH\", \"best_val_MAE\", \"best_val_RMSE\", \"best_val_R2\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a65e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.816496580927726"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.\n",
    "np.std([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "009107df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: logs\\spatial_cv_region_best_metrics_test.csv\n",
      "Saved: logs\\spatial_cv_region_best_metrics_train.csv\n",
      "Saved: logs\\DeepDemand_spatial_cv_summary.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Summarise best TRAIN and VALIDATION metrics per spatial-CV region\n",
    "and compute spatial-CV mean/std for DeepDemand.\n",
    "\n",
    "Outputs\n",
    "-------\n",
    "1) logs/spatial_cv_region_best_metrics_test.csv\n",
    "2) logs/spatial_cv_region_best_metrics_train.csv\n",
    "3) logs/DeepDemand_spatial_cv_summary.csv\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "LOG_DIR = Path(\"logs\")\n",
    "LOG_TEMPLATE = \"spatial_cv_{i}.log\"\n",
    "OUT_TEST = LOG_DIR / \"spatial_cv_region_best_metrics_test.csv\"\n",
    "OUT_TRAIN = LOG_DIR / \"spatial_cv_region_best_metrics_train.csv\"\n",
    "OUT_SUMMARY = LOG_DIR / \"DeepDemand_spatial_cv_summary.csv\"\n",
    "\n",
    "MODEL_NAME = \"DeepDemand\"\n",
    "\n",
    "REGION_CODE_BY_I = {\n",
    "    1: \"E12000001\",\n",
    "    2: \"E12000002\",\n",
    "    3: \"E12000003\",\n",
    "    4: \"E12000004\",\n",
    "    5: \"E12000005\",\n",
    "    6: \"E12000006\",\n",
    "    7: \"E12000007\",\n",
    "    8: \"E12000008\",\n",
    "    9: \"E12000009\",\n",
    "}\n",
    "\n",
    "REGION_NAME_BY_CODE = {\n",
    "    \"E12000001\": \"North East\",\n",
    "    \"E12000002\": \"North West\",\n",
    "    \"E12000003\": \"Yorkshire and the Humber\",\n",
    "    \"E12000004\": \"East Midlands\",\n",
    "    \"E12000005\": \"West Midlands\",\n",
    "    \"E12000006\": \"East of England\",\n",
    "    \"E12000007\": \"London\",\n",
    "    \"E12000008\": \"South East\",\n",
    "    \"E12000009\": \"South West\",\n",
    "}\n",
    "\n",
    "FLOAT = r\"[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?\"\n",
    "\n",
    "# Validation pattern\n",
    "pattern_val = re.compile(\n",
    "    rf\"Epoch\\s+(?P<epoch>\\d+)\\s+Step\\s+(?P<step>\\d+)\\s+Validation\\s+Eval:\\s*\"\n",
    "    rf\"RMSE:\\s*(?P<rmse>{FLOAT}),\\s*MAE:\\s*(?P<mae>{FLOAT}),\\s*MGEH:\\s*(?P<mgeh>{FLOAT}),\\s*R2:\\s*(?P<r2>{FLOAT})\",\n",
    "    re.IGNORECASE,\n",
    ")\n",
    "\n",
    "# Training pattern\n",
    "pattern_train = re.compile(\n",
    "    rf\"Epoch\\s+(?P<epoch>\\d+)\\s+Step\\s+(?P<step>\\d+)\\s+Train\\s+Eval:\\s*\"\n",
    "    rf\"RMSE:\\s*(?P<rmse>{FLOAT}),\\s*MAE:\\s*(?P<mae>{FLOAT}),\\s*MGEH:\\s*(?P<mgeh>{FLOAT}),\\s*R2:\\s*(?P<r2>{FLOAT})\",\n",
    "    re.IGNORECASE,\n",
    ")\n",
    "\n",
    "def parse_records(text: str, pattern):\n",
    "    rows = []\n",
    "    idx = 0\n",
    "    for m in pattern.finditer(text):\n",
    "        idx += 1\n",
    "        g = m.groupdict()\n",
    "        rows.append({\n",
    "            \"eval_idx\": idx,\n",
    "            \"epoch\": int(g[\"epoch\"]),\n",
    "            \"step\": int(g[\"step\"]),\n",
    "            \"rmse\": float(g[\"rmse\"]),\n",
    "            \"mae\": float(g[\"mae\"]),\n",
    "            \"mgeh\": float(g[\"mgeh\"]),\n",
    "            \"r2\": float(g[\"r2\"]),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def best_min(df, col):\n",
    "    if df.empty:\n",
    "        return None, None\n",
    "    i = df[col].idxmin()\n",
    "    return float(df.loc[i, col]), int(df.loc[i, \"eval_idx\"])\n",
    "\n",
    "def best_max(df, col):\n",
    "    if df.empty:\n",
    "        return None, None\n",
    "    i = df[col].idxmax()\n",
    "    return float(df.loc[i, col]), int(df.loc[i, \"eval_idx\"])\n",
    "\n",
    "test_summaries = []\n",
    "train_summaries = []\n",
    "\n",
    "for i in range(1, 10):\n",
    "    code = REGION_CODE_BY_I[i]\n",
    "    region = REGION_NAME_BY_CODE.get(code, code)\n",
    "    log_path = LOG_DIR / LOG_TEMPLATE.format(i=i)\n",
    "\n",
    "    if not log_path.exists():\n",
    "        print(f\"[WARN] Missing log: {log_path}\")\n",
    "        continue\n",
    "\n",
    "    text = log_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "    df_test = parse_records(text, pattern_val)\n",
    "    df_train = parse_records(text, pattern_train)\n",
    "\n",
    "    # ---- TEST (validation fold) ----\n",
    "    rmse_best, _ = best_min(df_test, \"rmse\")\n",
    "    mae_best, _  = best_min(df_test, \"mae\")\n",
    "    mgeh_best, _ = best_min(df_test, \"mgeh\")\n",
    "    r2_best, _   = best_max(df_test, \"r2\")\n",
    "\n",
    "    test_summaries.append({\n",
    "        \"region\": region,\n",
    "        \"RMSE\": rmse_best,\n",
    "        \"MAE\": mae_best,\n",
    "        \"MGEH\": mgeh_best,\n",
    "        \"R2\": r2_best,\n",
    "    })\n",
    "\n",
    "    # ---- TRAIN ----\n",
    "    rmse_best_t, _ = best_min(df_train, \"rmse\")\n",
    "    mae_best_t, _  = best_min(df_train, \"mae\")\n",
    "    mgeh_best_t, _ = best_min(df_train, \"mgeh\")\n",
    "    r2_best_t, _   = best_max(df_train, \"r2\")\n",
    "\n",
    "    train_summaries.append({\n",
    "        \"region\": region,\n",
    "        \"RMSE\": rmse_best_t,\n",
    "        \"MAE\": mae_best_t,\n",
    "        \"MGEH\": mgeh_best_t,\n",
    "        \"R2\": r2_best_t,\n",
    "    })\n",
    "\n",
    "# Convert to DataFrames\n",
    "df_test = pd.DataFrame(test_summaries).sort_values(\"region\").reset_index(drop=True)\n",
    "df_train = pd.DataFrame(train_summaries).sort_values(\"region\").reset_index(drop=True)\n",
    "\n",
    "df_test.to_csv(OUT_TEST, index=False)\n",
    "df_train.to_csv(OUT_TRAIN, index=False)\n",
    "\n",
    "print(f\"Saved: {OUT_TEST}\")\n",
    "print(f\"Saved: {OUT_TRAIN}\")\n",
    "\n",
    "# --------------------------\n",
    "# Spatial CV summary (mean ± std)\n",
    "# --------------------------\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "for split_name, df in [(\"Train\", df_train), (\"Test\", df_test)]:\n",
    "    for metric in [\"RMSE\", \"MAE\", \"MGEH\", \"R2\"]:\n",
    "        mean_val = df[metric].mean()\n",
    "        std_val  = df[metric].std(ddof=1)\n",
    "\n",
    "        summary_rows.append({\n",
    "            \"model\": MODEL_NAME,\n",
    "            \"split\": split_name,\n",
    "            \"metric\": metric,\n",
    "            \"mean\": mean_val,\n",
    "            \"std\": std_val,\n",
    "            \"mean_std\": f\"{mean_val:.4f} ± {std_val:.4f}\"\n",
    "        })\n",
    "\n",
    "df_summary = pd.DataFrame(summary_rows)\n",
    "df_summary.to_csv(OUT_SUMMARY, index=False)\n",
    "\n",
    "print(f\"Saved: {OUT_SUMMARY}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dc4666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
