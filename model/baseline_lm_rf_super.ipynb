{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Baseline models for DeepDemand: Ridge (L2) and Random Forest\n",
        "\n",
        "This notebook builds edge-level features from your existing data layout and evaluates:\n",
        "- 5-fold random CV (k=5)\n",
        "- 9-fold spatial CV (regions, fold_idx=1..9)\n",
        "\n",
        "Metrics (train/test): MGEH, MAE, R² using your `model.utils` functions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df1fc1aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "# path setting\n",
        "import sys\n",
        "from pathlib import Path\n",
        "# set the notebook's CWD to your repo root\n",
        "%cd D:/deepdemand\n",
        "ROOT = Path.cwd().parents[0]   # go up one level\n",
        "sys.path.insert(0, str(ROOT))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from config import DATA, TRAINING\n",
        "from model.dataloader import load_gt, load_json, get_lsoa_vector\n",
        "import model.utils as utils\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) Reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x24d3839cd10>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.random.seed(TRAINING['seed'])\n",
        "torch.manual_seed(TRAINING['seed'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Load GT and feature bank (same logic as your trainer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of valid edges: 5088\n",
            "\n",
            "=== GT Descriptive Statistics (raw) ===\n",
            "Min     : 191.405\n",
            "Max     : 113436.372\n",
            "Mean    : 25243.410\n",
            "Median  : 20618.627\n",
            "Std     : 18893.461\n",
            "======================================\n",
            "\n",
            "Edges: 5088 Scaler: None\n",
            "LSOA feature dim: 121\n"
          ]
        }
      ],
      "source": [
        "# --- Load GT (already filtered + optionally normalized) ---\n",
        "edge_to_gt, scaler = load_gt()\n",
        "all_edge_ids = list(edge_to_gt.keys())\n",
        "print('Edges:', len(all_edge_ids), 'Scaler:', type(scaler).__name__ if scaler else None)\n",
        "\n",
        "# --- Load LSOA features JSON + node_to_lsoa mapping ---\n",
        "lsoa_json = load_json(DATA['lsoa_json'])\n",
        "node_to_lsoa = load_json('data/node_features/node_to_lsoa.json')\n",
        "\n",
        "# --- Build feature_bank like your trainer ---\n",
        "lsoa_codes = sorted(lsoa_json.keys())\n",
        "feat_rows = []\n",
        "for code in lsoa_codes:\n",
        "    v = get_lsoa_vector(lsoa_json[code])  # torch tensor\n",
        "    feat_rows.append(v.cpu().numpy())\n",
        "X_lsoa = np.vstack(feat_rows).astype(np.float32)\n",
        "\n",
        "feature_bank = {code: X_lsoa[i] for i, code in enumerate(lsoa_codes)}\n",
        "\n",
        "feat_dim = X_lsoa.shape[1]\n",
        "print('LSOA feature dim:', feat_dim)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Edge-level feature construction (frequency-weighted)\n",
        "\n",
        "For each edge_id, we read:\n",
        "- `data/subgraphs/subgraphs/{edge_id}/od_use.feather` columns: O, D, t_OD\n",
        "\n",
        "We build:\n",
        "- XO: frequency-weighted mean of unique O nodes' LSOA vectors\n",
        "- XD: frequency-weighted mean of unique D nodes' LSOA vectors\n",
        "- t summary: mean, std, p10, p50, p90\n",
        "- interaction: XO * XD (enabled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "da22b9a6",
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "SUBGRAPH_ROOT = 'data/subgraphs/subgraphs'\n",
        "\n",
        "# T_STATS = ('mean', 'std', 'p10', 'p50', 'p90')\n",
        "T_STATS = ('mean')\n",
        "USE_INTERACTION = False\n",
        "\n",
        "def _get_lsoa_vec_from_node(node_id_str: str) -> np.ndarray:\n",
        "    lsoa_code = node_to_lsoa[str(node_id_str)][0]\n",
        "    return feature_bank[lsoa_code]\n",
        "\n",
        "def _compute_global_t_imputer(edge_ids: list) -> np.ndarray:\n",
        "    feats = []\n",
        "    empty_or_missing = 0\n",
        "\n",
        "    for eid in edge_ids:\n",
        "        fpath = os.path.join(SUBGRAPH_ROOT, eid, 'od_use.feather')\n",
        "        if not os.path.exists(fpath):\n",
        "            empty_or_missing += 1\n",
        "            continue\n",
        "        try:\n",
        "            df = pd.read_feather(fpath, columns=['t_OD'])\n",
        "        except Exception:\n",
        "            empty_or_missing += 1\n",
        "            continue\n",
        "        if len(df) == 0:\n",
        "            empty_or_missing += 1\n",
        "            continue\n",
        "\n",
        "        t = df['t_OD'].to_numpy(dtype=np.float32)\n",
        "        t_feat = []\n",
        "        if 'mean' in T_STATS: t_feat.append(float(np.mean(t)))\n",
        "        if 'std'  in T_STATS: t_feat.append(float(np.std(t)))\n",
        "        if 'p10'  in T_STATS: t_feat.append(float(np.percentile(t, 10)))\n",
        "        if 'p50'  in T_STATS: t_feat.append(float(np.percentile(t, 50)))\n",
        "        if 'p90'  in T_STATS: t_feat.append(float(np.percentile(t, 90)))\n",
        "        feats.append(t_feat)\n",
        "\n",
        "    if len(feats) == 0:\n",
        "        print(\"[t_imputer] No non-empty od_use found. Using zeros for t_stats.\")\n",
        "        return np.zeros((len(T_STATS),), dtype=np.float32)\n",
        "\n",
        "    feats = np.asarray(feats, dtype=np.float32)\n",
        "    global_mean = feats.mean(axis=0).astype(np.float32)\n",
        "    print(f\"[t_imputer] Computed from {len(feats)} non-empty edges; \"\n",
        "          f\"{empty_or_missing} empty/missing edges will use global mean t_stats.\")\n",
        "    return global_mean\n",
        "\n",
        "def build_one_edge_feature(\n",
        "    edge_id: str,\n",
        "    t_imputer: np.ndarray,\n",
        "    eps: float = 1e-6\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    If od_use.feather is missing/empty:\n",
        "      - XO, XD = zeros\n",
        "      - t_feat = t_imputer\n",
        "      - n_od = 0\n",
        "    Else:\n",
        "      - compute XO, XD, t_feat\n",
        "      - n_od = len(df)\n",
        "    Returns: concat([XO, XD, XO*XD (optional), t_feat, n_od])\n",
        "    \"\"\"\n",
        "    fpath = os.path.join(SUBGRAPH_ROOT, edge_id, 'od_use.feather')\n",
        "\n",
        "    # defaults for zero-OD edges\n",
        "    XO = np.zeros((feat_dim,), dtype=np.float32)\n",
        "    XD = np.zeros((feat_dim,), dtype=np.float32)\n",
        "    t_feat = t_imputer.copy()\n",
        "    n_od = 0.0\n",
        "\n",
        "    if os.path.exists(fpath):\n",
        "        try:\n",
        "            df = pd.read_feather(fpath, columns=['O', 'D', 't_OD'])\n",
        "        except Exception:\n",
        "            df = None\n",
        "\n",
        "        if df is not None and len(df) > 0:\n",
        "            n_od = float(len(df))\n",
        "\n",
        "            O = df['O'].astype(str).tolist()\n",
        "            D = df['D'].astype(str).tolist()\n",
        "            t = df['t_OD'].to_numpy(dtype=np.float32)\n",
        "\n",
        "            # frequency weights\n",
        "            cO = Counter(O)\n",
        "            cD = Counter(D)\n",
        "\n",
        "            uniq_O = list(dict.fromkeys(O))\n",
        "            uniq_D = list(dict.fromkeys(D))\n",
        "\n",
        "            wO = np.array([float(cO[n]) for n in uniq_O], dtype=np.float32)\n",
        "            wD = np.array([float(cD[n]) for n in uniq_D], dtype=np.float32)\n",
        "            wO = wO / (wO.sum() + eps)\n",
        "            wD = wD / (wD.sum() + eps)\n",
        "\n",
        "            XO = np.zeros((feat_dim,), dtype=np.float32)\n",
        "            for n, w in zip(uniq_O, wO):\n",
        "                XO += w * _get_lsoa_vec_from_node(n)\n",
        "\n",
        "            XD = np.zeros((feat_dim,), dtype=np.float32)\n",
        "            for n, w in zip(uniq_D, wD):\n",
        "                XD += w * _get_lsoa_vec_from_node(n)\n",
        "\n",
        "            # t stats (edge-specific)\n",
        "            t_edge = []\n",
        "            if 'mean' in T_STATS: t_edge.append(float(np.mean(t)))\n",
        "            if 'std'  in T_STATS: t_edge.append(float(np.std(t)))\n",
        "            if 'p10'  in T_STATS: t_edge.append(float(np.percentile(t, 10)))\n",
        "            if 'p50'  in T_STATS: t_edge.append(float(np.percentile(t, 50)))\n",
        "            if 'p90'  in T_STATS: t_edge.append(float(np.percentile(t, 90)))\n",
        "            t_feat = np.asarray(t_edge, dtype=np.float32)\n",
        "\n",
        "    parts = [XO, XD]\n",
        "    if USE_INTERACTION:\n",
        "        parts.append(XO * XD)\n",
        "    parts.append(t_feat)\n",
        "    # parts.append(np.array([n_od], dtype=np.float32))  # <-- add n_od as a feature\n",
        "    return np.concatenate(parts, axis=0)\n",
        "\n",
        "def build_dataset(edge_ids: list) -> tuple[np.ndarray, np.ndarray, list]:\n",
        "    t_imputer = _compute_global_t_imputer(edge_ids)\n",
        "\n",
        "    X_rows = []\n",
        "    y_rows = []\n",
        "    kept = []\n",
        "\n",
        "    for eid in edge_ids:\n",
        "        x = build_one_edge_feature(eid, t_imputer=t_imputer)\n",
        "        X_rows.append(x)\n",
        "        y_rows.append(float(edge_to_gt[eid]))\n",
        "        kept.append(eid)\n",
        "\n",
        "    X = np.vstack(X_rows).astype(np.float32)\n",
        "    y = np.array(y_rows, dtype=np.float32)\n",
        "    return X, y, kept"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7142b76",
      "metadata": {},
      "source": [
        "### Build full dataset once\n",
        "We build features once and then just slice by fold IDs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d5d623ea",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[t_imputer] Computed from 4584 non-empty edges; 504 empty/missing edges will use global mean t_stats.\n",
            "Built X: (5088, 243) y: (5088,)\n"
          ]
        }
      ],
      "source": [
        "X_all, y_all, kept_edges = build_dataset(all_edge_ids)\n",
        "print('Built X:', X_all.shape, 'y:', y_all.shape)\n",
        "\n",
        "# Map edge_id -> row index\n",
        "edge_to_idx = {eid: i for i, eid in enumerate(kept_edges)}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9786d3c",
      "metadata": {},
      "source": [
        "## 3) Models: Ridge (L2) and Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6edae89d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6c54bc4f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_ridge(alpha: float = 1.0):\n",
        "    return Pipeline([\n",
        "        ('scaler', StandardScaler(with_mean=True, with_std=True)),\n",
        "        ('ridge', Ridge(alpha=alpha, random_state=TRAINING['seed']))\n",
        "    ])\n",
        "\n",
        "def make_rf(n_estimators: int = 500, max_depth=None, n_jobs: int = -1):\n",
        "    return RandomForestRegressor(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        random_state=TRAINING['seed'],\n",
        "        n_jobs=n_jobs,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0770ae9",
      "metadata": {},
      "source": [
        "## 4) Metrics (use your exact definitions)\n",
        "\n",
        "We compute metrics in the same way as your training loop:\n",
        "- pass **normalized y** into utils and provide the scaler to invert (if enabled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "79a7b126",
      "metadata": {},
      "outputs": [],
      "source": [
        "def eval_metrics(y_true_np: np.ndarray, y_pred_np: np.ndarray, scaler):\n",
        "    # utils expects torch tensors\n",
        "    yt = torch.tensor(y_true_np, dtype=torch.float32)\n",
        "    yp = torch.tensor(y_pred_np, dtype=torch.float32)\n",
        "    mae = utils.MAE(yt, yp, scaler).item()\n",
        "    mgeh = utils.MGEH(yt, yp, scaler).item()\n",
        "    r2 = utils.R_square(yt, yp, scaler).item()\n",
        "    return {'MAE': mae, 'MGEH': mgeh, 'R2': r2}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "780863ce",
      "metadata": {},
      "source": [
        "## 5) Fold runners\n",
        "\n",
        "- 5-fold CV: `utils.get_cv_split(..., k=5, fold_idx=0..4)`\n",
        "- 9-fold spatial CV: `utils.get_spatial_cv_split(..., fold_idx=1..9)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "25442ebd",
      "metadata": {},
      "outputs": [],
      "source": [
        "def ids_to_indices(ids: list[str]) -> np.ndarray:\n",
        "    idx = [edge_to_idx[e] for e in ids if e in edge_to_idx]\n",
        "    return np.array(idx, dtype=np.int64)\n",
        "\n",
        "def run_cv(model_name: str, model_factory, split_type: str):\n",
        "    results = []\n",
        "\n",
        "    if split_type == 'kfold5':\n",
        "        folds = list(range(5))\n",
        "        for fold_idx in folds:\n",
        "            train_ids, test_ids = utils.get_cv_split(\n",
        "                kept_edges,\n",
        "                k=5,\n",
        "                fold_idx=fold_idx,\n",
        "                seed=TRAINING['seed'],\n",
        "            )\n",
        "            tr = ids_to_indices(train_ids)\n",
        "            te = ids_to_indices(test_ids)\n",
        "\n",
        "            model = model_factory()\n",
        "            model.fit(X_all[tr], y_all[tr])\n",
        "            pred_tr = model.predict(X_all[tr])\n",
        "            pred_te = model.predict(X_all[te])\n",
        "\n",
        "            m_tr = eval_metrics(y_all[tr], pred_tr, scaler)\n",
        "            m_te = eval_metrics(y_all[te], pred_te, scaler)\n",
        "\n",
        "            results.append({\n",
        "                'split': 'kfold5',\n",
        "                'fold': fold_idx,\n",
        "                'model': model_name,\n",
        "                'train_MAE': m_tr['MAE'],\n",
        "                'train_MGEH': m_tr['MGEH'],\n",
        "                'train_R2': m_tr['R2'],\n",
        "                'test_MAE': m_te['MAE'],\n",
        "                'test_MGEH': m_te['MGEH'],\n",
        "                'test_R2': m_te['R2'],\n",
        "            })\n",
        "\n",
        "    elif split_type == 'spatial9':\n",
        "        folds = list(range(1, 10))  # 1..9\n",
        "        for fold_idx in folds:\n",
        "            train_ids, test_ids = utils.get_spatial_cv_split(\n",
        "                kept_edges,\n",
        "                fold_idx=fold_idx,\n",
        "            )\n",
        "            tr = ids_to_indices(train_ids)\n",
        "            te = ids_to_indices(test_ids)\n",
        "\n",
        "            model = model_factory()\n",
        "            model.fit(X_all[tr], y_all[tr])\n",
        "            pred_tr = model.predict(X_all[tr])\n",
        "            pred_te = model.predict(X_all[te])\n",
        "\n",
        "            m_tr = eval_metrics(y_all[tr], pred_tr, scaler)\n",
        "            m_te = eval_metrics(y_all[te], pred_te, scaler)\n",
        "\n",
        "            results.append({\n",
        "                'split': 'spatial9',\n",
        "                'fold': fold_idx,\n",
        "                'model': model_name,\n",
        "                'train_MAE': m_tr['MAE'],\n",
        "                'train_MGEH': m_tr['MGEH'],\n",
        "                'train_R2': m_tr['R2'],\n",
        "                'test_MAE': m_te['MAE'],\n",
        "                'test_MGEH': m_te['MGEH'],\n",
        "                'test_R2': m_te['R2'],\n",
        "            })\n",
        "    else:\n",
        "        raise ValueError('split_type must be kfold5 or spatial9')\n",
        "\n",
        "    return pd.DataFrame(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59949e48",
      "metadata": {},
      "source": [
        "## 6) Run baselines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "65b3e994",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Spatial CV] Validation region: E12000001\n",
            "[Spatial CV] #val_edges = 143, #train_edges = 4945\n",
            "[Spatial CV] Validation region: E12000002\n",
            "[Spatial CV] #val_edges = 608, #train_edges = 4480\n",
            "[Spatial CV] Validation region: E12000003\n",
            "[Spatial CV] #val_edges = 580, #train_edges = 4508\n",
            "[Spatial CV] Validation region: E12000004\n",
            "[Spatial CV] #val_edges = 426, #train_edges = 4662\n",
            "[Spatial CV] Validation region: E12000005\n",
            "[Spatial CV] #val_edges = 480, #train_edges = 4608\n",
            "[Spatial CV] Validation region: E12000006\n",
            "[Spatial CV] #val_edges = 667, #train_edges = 4421\n",
            "[Spatial CV] Validation region: E12000007\n",
            "[Spatial CV] #val_edges = 85, #train_edges = 5003\n",
            "[Spatial CV] Validation region: E12000008\n",
            "[Spatial CV] #val_edges = 957, #train_edges = 4131\n",
            "[Spatial CV] Validation region: E12000009\n",
            "[Spatial CV] #val_edges = 392, #train_edges = 4696\n",
            "[Spatial CV] Validation region: E12000001\n",
            "[Spatial CV] #val_edges = 143, #train_edges = 4945\n",
            "[Spatial CV] Validation region: E12000002\n",
            "[Spatial CV] #val_edges = 608, #train_edges = 4480\n",
            "[Spatial CV] Validation region: E12000003\n",
            "[Spatial CV] #val_edges = 580, #train_edges = 4508\n",
            "[Spatial CV] Validation region: E12000004\n",
            "[Spatial CV] #val_edges = 426, #train_edges = 4662\n",
            "[Spatial CV] Validation region: E12000005\n",
            "[Spatial CV] #val_edges = 480, #train_edges = 4608\n",
            "[Spatial CV] Validation region: E12000006\n",
            "[Spatial CV] #val_edges = 667, #train_edges = 4421\n",
            "[Spatial CV] Validation region: E12000007\n",
            "[Spatial CV] #val_edges = 85, #train_edges = 5003\n",
            "[Spatial CV] Validation region: E12000008\n",
            "[Spatial CV] #val_edges = 957, #train_edges = 4131\n",
            "[Spatial CV] Validation region: E12000009\n",
            "[Spatial CV] #val_edges = 392, #train_edges = 4696\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>split</th>\n",
              "      <th>fold</th>\n",
              "      <th>model</th>\n",
              "      <th>train_MAE</th>\n",
              "      <th>train_MGEH</th>\n",
              "      <th>train_R2</th>\n",
              "      <th>test_MAE</th>\n",
              "      <th>test_MGEH</th>\n",
              "      <th>test_R2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>kfold5</td>\n",
              "      <td>0</td>\n",
              "      <td>Ridge</td>\n",
              "      <td>12218.013672</td>\n",
              "      <td>78.516602</td>\n",
              "      <td>0.318634</td>\n",
              "      <td>12903.316406</td>\n",
              "      <td>82.459572</td>\n",
              "      <td>0.188255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kfold5</td>\n",
              "      <td>1</td>\n",
              "      <td>Ridge</td>\n",
              "      <td>12085.897461</td>\n",
              "      <td>77.946404</td>\n",
              "      <td>0.316429</td>\n",
              "      <td>13157.112305</td>\n",
              "      <td>83.750801</td>\n",
              "      <td>0.251117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>kfold5</td>\n",
              "      <td>2</td>\n",
              "      <td>Ridge</td>\n",
              "      <td>12275.780273</td>\n",
              "      <td>79.033234</td>\n",
              "      <td>0.306328</td>\n",
              "      <td>12551.689453</td>\n",
              "      <td>80.523827</td>\n",
              "      <td>0.272058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>kfold5</td>\n",
              "      <td>3</td>\n",
              "      <td>Ridge</td>\n",
              "      <td>12182.669922</td>\n",
              "      <td>78.597954</td>\n",
              "      <td>0.312257</td>\n",
              "      <td>13024.542969</td>\n",
              "      <td>81.261765</td>\n",
              "      <td>0.147523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>kfold5</td>\n",
              "      <td>4</td>\n",
              "      <td>Ridge</td>\n",
              "      <td>12158.456055</td>\n",
              "      <td>78.503624</td>\n",
              "      <td>0.323467</td>\n",
              "      <td>12968.589844</td>\n",
              "      <td>81.260834</td>\n",
              "      <td>0.163925</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    split  fold  model     train_MAE  train_MGEH  train_R2      test_MAE  \\\n",
              "0  kfold5     0  Ridge  12218.013672   78.516602  0.318634  12903.316406   \n",
              "1  kfold5     1  Ridge  12085.897461   77.946404  0.316429  13157.112305   \n",
              "2  kfold5     2  Ridge  12275.780273   79.033234  0.306328  12551.689453   \n",
              "3  kfold5     3  Ridge  12182.669922   78.597954  0.312257  13024.542969   \n",
              "4  kfold5     4  Ridge  12158.456055   78.503624  0.323467  12968.589844   \n",
              "\n",
              "   test_MGEH   test_R2  \n",
              "0  82.459572  0.188255  \n",
              "1  83.750801  0.251117  \n",
              "2  80.523827  0.272058  \n",
              "3  81.261765  0.147523  \n",
              "4  81.260834  0.163925  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ridge settings (tune alpha if you want)\n",
        "RIDGE_ALPHA = 1.0\n",
        "\n",
        "# RF settings (adjust if too slow)\n",
        "RF_TREES = 500\n",
        "RF_MAX_DEPTH = None\n",
        "\n",
        "ridge_factory = lambda: make_ridge(alpha=RIDGE_ALPHA)\n",
        "rf_factory    = lambda: make_rf(n_estimators=RF_TREES, max_depth=RF_MAX_DEPTH)\n",
        "\n",
        "df_ridge_k5 = run_cv('Ridge', ridge_factory, 'kfold5')\n",
        "df_rf_k5    = run_cv('RF',    rf_factory,    'kfold5')\n",
        "\n",
        "df_ridge_sp = run_cv('Ridge', ridge_factory, 'spatial9')\n",
        "df_rf_sp    = run_cv('RF',    rf_factory,    'spatial9')\n",
        "\n",
        "df_all = pd.concat([df_ridge_k5, df_rf_k5, df_ridge_sp, df_rf_sp], ignore_index=True)\n",
        "df_all.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4c9d1cf",
      "metadata": {},
      "source": [
        "## 7) Summaries (mean ± std across folds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d5c8f0fc",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>split</th>\n",
              "      <th>model</th>\n",
              "      <th>train_MAE_mean</th>\n",
              "      <th>train_MGEH_mean</th>\n",
              "      <th>train_R2_mean</th>\n",
              "      <th>test_MAE_mean</th>\n",
              "      <th>test_MGEH_mean</th>\n",
              "      <th>test_R2_mean</th>\n",
              "      <th>train_MAE_std</th>\n",
              "      <th>train_MGEH_std</th>\n",
              "      <th>train_R2_std</th>\n",
              "      <th>test_MAE_std</th>\n",
              "      <th>test_MGEH_std</th>\n",
              "      <th>test_R2_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>kfold5</td>\n",
              "      <td>RF</td>\n",
              "      <td>3096.523828</td>\n",
              "      <td>23.728201</td>\n",
              "      <td>0.942049</td>\n",
              "      <td>7453.121094</td>\n",
              "      <td>50.558841</td>\n",
              "      <td>0.700684</td>\n",
              "      <td>18.288058</td>\n",
              "      <td>0.175644</td>\n",
              "      <td>0.000818</td>\n",
              "      <td>155.723144</td>\n",
              "      <td>1.064574</td>\n",
              "      <td>0.027510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kfold5</td>\n",
              "      <td>Ridge</td>\n",
              "      <td>12184.163477</td>\n",
              "      <td>78.519563</td>\n",
              "      <td>0.315423</td>\n",
              "      <td>12921.050195</td>\n",
              "      <td>81.851360</td>\n",
              "      <td>0.204576</td>\n",
              "      <td>70.460601</td>\n",
              "      <td>0.386904</td>\n",
              "      <td>0.006496</td>\n",
              "      <td>226.626310</td>\n",
              "      <td>1.268512</td>\n",
              "      <td>0.054529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spatial9</td>\n",
              "      <td>RF</td>\n",
              "      <td>3015.366130</td>\n",
              "      <td>23.191407</td>\n",
              "      <td>0.943371</td>\n",
              "      <td>9408.919054</td>\n",
              "      <td>61.174131</td>\n",
              "      <td>0.503046</td>\n",
              "      <td>42.149083</td>\n",
              "      <td>0.180442</td>\n",
              "      <td>0.001937</td>\n",
              "      <td>1820.438511</td>\n",
              "      <td>7.477283</td>\n",
              "      <td>0.119772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>spatial9</td>\n",
              "      <td>Ridge</td>\n",
              "      <td>12169.063585</td>\n",
              "      <td>78.460800</td>\n",
              "      <td>0.312150</td>\n",
              "      <td>13590.974175</td>\n",
              "      <td>86.107700</td>\n",
              "      <td>0.039495</td>\n",
              "      <td>228.011606</td>\n",
              "      <td>0.925877</td>\n",
              "      <td>0.006300</td>\n",
              "      <td>2461.714252</td>\n",
              "      <td>8.494967</td>\n",
              "      <td>0.324650</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      split  model  train_MAE_mean  train_MGEH_mean  train_R2_mean  \\\n",
              "0    kfold5     RF     3096.523828        23.728201       0.942049   \n",
              "1    kfold5  Ridge    12184.163477        78.519563       0.315423   \n",
              "2  spatial9     RF     3015.366130        23.191407       0.943371   \n",
              "3  spatial9  Ridge    12169.063585        78.460800       0.312150   \n",
              "\n",
              "   test_MAE_mean  test_MGEH_mean  test_R2_mean  train_MAE_std  train_MGEH_std  \\\n",
              "0    7453.121094       50.558841      0.700684      18.288058        0.175644   \n",
              "1   12921.050195       81.851360      0.204576      70.460601        0.386904   \n",
              "2    9408.919054       61.174131      0.503046      42.149083        0.180442   \n",
              "3   13590.974175       86.107700      0.039495     228.011606        0.925877   \n",
              "\n",
              "   train_R2_std  test_MAE_std  test_MGEH_std  test_R2_std  \n",
              "0      0.000818    155.723144       1.064574     0.027510  \n",
              "1      0.006496    226.626310       1.268512     0.054529  \n",
              "2      0.001937   1820.438511       7.477283     0.119772  \n",
              "3      0.006300   2461.714252       8.494967     0.324650  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def summarize(df: pd.DataFrame):\n",
        "    metrics = ['train_MAE','train_MGEH','train_R2','test_MAE','test_MGEH','test_R2']\n",
        "    g = df.groupby(['split','model'])[metrics]\n",
        "    mean = g.mean().add_suffix('_mean')\n",
        "    std  = g.std(ddof=1).add_suffix('_std')\n",
        "    out = pd.concat([mean, std], axis=1).reset_index()\n",
        "    return out\n",
        "\n",
        "summary = summarize(df_all)\n",
        "summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d643393",
      "metadata": {},
      "source": [
        "## 8) Save outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "27276d56",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved:\n",
            " - eval/baselines/baseline_ridge_rf_all_folds.csv\n",
            " - eval/baselines/baseline_ridge_rf_summary.csv\n"
          ]
        }
      ],
      "source": [
        "os.makedirs('eval/baselines', exist_ok=True)\n",
        "df_all.to_csv('eval/baselines/baseline_ridge_rf_all_folds.csv', index=False)\n",
        "summary.to_csv('eval/baselines/baseline_ridge_rf_summary.csv', index=False)\n",
        "print('Saved:')\n",
        "print(' - eval/baselines/baseline_ridge_rf_all_folds.csv')\n",
        "print(' - eval/baselines/baseline_ridge_rf_summary.csv')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch_gpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
