{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "598f6bf2",
      "metadata": {},
      "source": [
        "# Gravity-interaction baseline for DeepDemand (distance-decay gravity regression)\n",
        "\n",
        "This notebook:\n",
        "- Loads GT via `load_gt()` (same filtering/normalization as DeepDemand)\n",
        "- Loads **raw** LSOA features JSON (same structure as normalized)\n",
        "- Defines mass per LSOA: `mass = population_total(level) + employment_total(level)`\n",
        "- For each edge, aggregates OD pairs: `S_e(gamma) = sum( M_O * M_D * exp(-gamma * t_OD) )`\n",
        "- Fits log-linear regression: `log(y) = a0 + a1 * log(S + eps)`\n",
        "- Chooses gamma per fold via a small inner split on training edges\n",
        "- Evaluates 5-fold CV and 9-fold spatial CV\n",
        "- Reports train/test metrics: MGEH, MAE, R2 using your `utils` definitions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb494af5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# path setting\n",
        "import sys\n",
        "from pathlib import Path\n",
        "# set the notebook's CWD to your repo root\n",
        "%cd D:/deepdemand\n",
        "ROOT = Path.cwd().parents[0]   # go up one level\n",
        "sys.path.insert(0, str(ROOT))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5688af4d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from config import DATA, TRAINING\n",
        "from model.dataloader import load_gt, load_json\n",
        "import model.utils as utils\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20db9390",
      "metadata": {},
      "source": [
        "## 0) Reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "eac90c97",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x1f5cd5b4c50>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.random.seed(TRAINING['seed'])\n",
        "torch.manual_seed(TRAINING['seed'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba4e575d",
      "metadata": {},
      "source": [
        "## 1) Load GT and RAW LSOA features\n",
        "\n",
        "You must set `RAW_LSOA_JSON_PATH` to your raw-feature JSON file.\n",
        "It has the same structure as the normalized file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ad9f13fc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of valid edges: 5088\n",
            "\n",
            "=== GT Descriptive Statistics (raw) ===\n",
            "Min     : 191.405\n",
            "Max     : 113436.372\n",
            "Mean    : 25243.410\n",
            "Median  : 20618.627\n",
            "Std     : 18893.461\n",
            "======================================\n",
            "\n",
            "Edges: 5088 Scaler: None\n",
            "Raw LSOAs: 35672\n"
          ]
        }
      ],
      "source": [
        "# ---- GT (filtered + maybe normalized) ----\n",
        "edge_to_gt, scaler = load_gt()\n",
        "all_edge_ids = list(edge_to_gt.keys())\n",
        "print('Edges:', len(all_edge_ids), 'Scaler:', type(scaler).__name__ if scaler else None)\n",
        "\n",
        "# ---- node -> LSOA mapping ----\n",
        "node_to_lsoa = load_json('data/node_features/node_to_lsoa.json')\n",
        "\n",
        "# ---- RAW LSOA features ----\n",
        "# Update this path to your raw JSON.\n",
        "RAW_LSOA_JSON_PATH = 'data/node_features/lsoa21_features_raw.json'\n",
        "raw_lsoa_json = load_json(RAW_LSOA_JSON_PATH)\n",
        "print('Raw LSOAs:', len(raw_lsoa_json))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "330cf768",
      "metadata": {},
      "source": [
        "## 2) Define mass per LSOA\n",
        "\n",
        "Mass is `population_total(level) + employment_total(level)`.\n",
        "\n",
        "We use the level specified in config:\n",
        "- `DATA['population_level']` (e.g. 'lv3')\n",
        "- `DATA['employment_level']` (e.g. 'lv3')\n",
        "\n",
        "In your example, the first element `[0]` is the total.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b83de9fe",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using mass levels: lv3 lv3\n",
            "Mass stats: min 991.0 mean 2496.8032069970845 max 392068.0\n"
          ]
        }
      ],
      "source": [
        "POP_LEVEL = DATA.get('population_level', 'lv3')\n",
        "EMP_LEVEL = DATA.get('employment_level', 'lv3')\n",
        "print('Using mass levels:', POP_LEVEL, EMP_LEVEL)\n",
        "\n",
        "def lsoa_mass(rec: dict) -> float:\n",
        "    pop = 0.0\n",
        "    emp = 0.0\n",
        "    if isinstance(rec.get('population'), dict):\n",
        "        arr = rec['population'].get(POP_LEVEL, [])\n",
        "        if len(arr) > 0:\n",
        "            pop = float(arr[0])\n",
        "    if isinstance(rec.get('employment'), dict):\n",
        "        arr = rec['employment'].get(EMP_LEVEL, [])\n",
        "        if len(arr) > 0:\n",
        "            emp = float(arr[0])\n",
        "    return pop + emp\n",
        "\n",
        "# Precompute LSOA -> mass\n",
        "lsoa_to_mass = {code: lsoa_mass(rec) for code, rec in raw_lsoa_json.items()}\n",
        "\n",
        "masses = np.array(list(lsoa_to_mass.values()), dtype=np.float64)\n",
        "print('Mass stats: min', masses.min(), 'mean', masses.mean(), 'max', masses.max())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f125db92",
      "metadata": {},
      "source": [
        "## 3) Preload OD data per edge (so we don’t keep reading in the gamma grid)\n",
        "\n",
        "For each edge_id we cache:\n",
        "- `n_od`\n",
        "- arrays of `mO`, `mD`, `t` for each OD pair\n",
        "\n",
        "If `od_use.feather` is missing/empty, we treat it as `n_od=0` and later predict 0.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "02968e41",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cached edges: 5088\n",
            "Edges with missing/empty OD: 504\n"
          ]
        }
      ],
      "source": [
        "SUBGRAPH_ROOT = 'data/subgraphs/subgraphs'\n",
        "\n",
        "def node_mass(node_id_str: str) -> float:\n",
        "    lsoa = node_to_lsoa[str(node_id_str)][0]\n",
        "    return float(lsoa_to_mass.get(lsoa, 0.0))\n",
        "\n",
        "edge_cache = {}  # edge_id -> dict(n_od, mO, mD, t)\n",
        "missing_or_empty = 0\n",
        "\n",
        "for eid in all_edge_ids:\n",
        "    fpath = os.path.join(SUBGRAPH_ROOT, eid, 'od_use.feather')\n",
        "    if not os.path.exists(fpath):\n",
        "        edge_cache[eid] = {'n_od': 0, 'mO': None, 'mD': None, 't': None}\n",
        "        missing_or_empty += 1\n",
        "        continue\n",
        "    try:\n",
        "        df = pd.read_feather(fpath, columns=['O','D','t_OD'])\n",
        "    except Exception:\n",
        "        edge_cache[eid] = {'n_od': 0, 'mO': None, 'mD': None, 't': None}\n",
        "        missing_or_empty += 1\n",
        "        continue\n",
        "\n",
        "    if len(df) == 0:\n",
        "        edge_cache[eid] = {'n_od': 0, 'mO': None, 'mD': None, 't': None}\n",
        "        missing_or_empty += 1\n",
        "        continue\n",
        "\n",
        "    O = df['O'].astype(str).tolist()\n",
        "    D = df['D'].astype(str).tolist()\n",
        "    t = df['t_OD'].to_numpy(dtype=np.float64)  # use float64 for stability in exp\n",
        "\n",
        "    mO = np.array([node_mass(o) for o in O], dtype=np.float64)\n",
        "    mD = np.array([node_mass(d) for d in D], dtype=np.float64)\n",
        "\n",
        "    edge_cache[eid] = {'n_od': int(len(df)), 'mO': mO, 'mD': mD, 't': t}\n",
        "\n",
        "print('Cached edges:', len(edge_cache))\n",
        "print('Edges with missing/empty OD:', missing_or_empty)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8eb25a9d",
      "metadata": {},
      "source": [
        "## 4) Gravity score and log-linear regression helper\n",
        "\n",
        "- For given gamma, compute `S_e(gamma)` for each edge.\n",
        "- Fit `log(y) ~ log(S + eps)` on edges with `n_od>0`.\n",
        "- Predict:\n",
        "  - if `n_od==0` => pred=0 (match DeepDemand)\n",
        "  - else => exp(a0 + a1 * log(S+eps))\n",
        "\n",
        "We evaluate metrics using your `utils` by converting raw predictions back to normalized space (if scaler exists).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5d42781e",
      "metadata": {},
      "outputs": [],
      "source": [
        "EPS_S = 1e-12  # for log(S+eps)\n",
        "EPS_Y = 1e-12  # for log(y+eps)\n",
        "\n",
        "def gravity_score_for_edges(edge_ids: list[str], gamma: float) -> np.ndarray:\n",
        "    S = np.zeros((len(edge_ids),), dtype=np.float64)\n",
        "    for i, eid in enumerate(edge_ids):\n",
        "        rec = edge_cache[eid]\n",
        "        if rec['n_od'] == 0:\n",
        "            S[i] = 0.0\n",
        "            continue\n",
        "        mO, mD, t = rec['mO'], rec['mD'], rec['t']\n",
        "        # sum( mO*mD*exp(-gamma*t) )\n",
        "        S[i] = np.sum((mO * mD) * np.exp(-gamma * t))\n",
        "    return S\n",
        "\n",
        "def fit_loglinear_on_train(edge_ids_train: list[str], y_train_raw: np.ndarray, S_train: np.ndarray):\n",
        "    # use only edges with OD pairs and positive-ish y\n",
        "    n_od = np.array([edge_cache[e]['n_od'] for e in edge_ids_train], dtype=np.int64)\n",
        "    mask = (n_od > 0)\n",
        "    # if your GT can be 0, keep it with EPS_Y; otherwise still safe\n",
        "    X = np.log(S_train[mask] + EPS_S).reshape(-1, 1)\n",
        "    y = np.log(y_train_raw[mask] + EPS_Y)\n",
        "    \n",
        "    model = LinearRegression()\n",
        "    model.fit(X, y)\n",
        "    return model\n",
        "\n",
        "def predict_raw(edge_ids: list[str], S: np.ndarray, model: LinearRegression) -> np.ndarray:\n",
        "    n_od = np.array([edge_cache[e]['n_od'] for e in edge_ids], dtype=np.int64)\n",
        "    pred = np.zeros((len(edge_ids),), dtype=np.float64)\n",
        "    mask = (n_od > 0)\n",
        "    if np.any(mask):\n",
        "        X = np.log(S[mask] + EPS_S).reshape(-1, 1)\n",
        "        logy = model.predict(X)\n",
        "        pred[mask] = np.exp(logy)\n",
        "    # n_od==0 stays 0\n",
        "    pred = np.clip(pred, 0.0, None)\n",
        "    return pred\n",
        "\n",
        "def raw_to_norm(y_raw: np.ndarray) -> np.ndarray:\n",
        "    if scaler is None:\n",
        "        return y_raw.astype(np.float32)\n",
        "    yt = torch.tensor(y_raw, dtype=torch.float32)\n",
        "    yn = scaler.transform(yt).cpu().numpy()\n",
        "    return yn.astype(np.float32)\n",
        "\n",
        "def norm_to_raw(y_norm: np.ndarray) -> np.ndarray:\n",
        "    if scaler is None:\n",
        "        return y_norm.astype(np.float64)\n",
        "    yt = torch.tensor(y_norm, dtype=torch.float32)\n",
        "    yr = scaler.inverse_transform(yt).cpu().numpy()\n",
        "    return yr.astype(np.float64)\n",
        "\n",
        "def eval_metrics(y_true_norm: np.ndarray, y_pred_norm: np.ndarray):\n",
        "    yt = torch.tensor(y_true_norm, dtype=torch.float32)\n",
        "    yp = torch.tensor(y_pred_norm, dtype=torch.float32)\n",
        "    return {\n",
        "        'MAE': utils.MAE(yt, yp, scaler).item(),\n",
        "        'MGEH': utils.MGEH(yt, yp, scaler).item(),\n",
        "        'R2': utils.R_square(yt, yp, scaler).item(),\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86f48366",
      "metadata": {},
      "source": [
        "## 5) Choose gamma via inner split (train-only)\n",
        "\n",
        "We do a simple inner holdout: 80% inner-train, 20% inner-val sampled from the outer training fold.\n",
        "We select gamma minimizing inner-val MGEH (you can change to MAE if you prefer).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5c8a9300",
      "metadata": {},
      "outputs": [],
      "source": [
        "def choose_gamma_inner(train_ids: list[str], y_train_norm: np.ndarray, gamma_grid: np.ndarray, inner_frac: float = 0.2):\n",
        "    rng = np.random.default_rng(TRAINING['seed'])\n",
        "    idx = np.arange(len(train_ids))\n",
        "    rng.shuffle(idx)\n",
        "    n_val = max(1, int(len(idx) * inner_frac))\n",
        "    idx_val = idx[:n_val]\n",
        "    idx_tr  = idx[n_val:]\n",
        "    if len(idx_tr) == 0:\n",
        "        idx_tr = idx_val\n",
        "\n",
        "    tr_ids = [train_ids[i] for i in idx_tr]\n",
        "    va_ids = [train_ids[i] for i in idx_val]\n",
        "\n",
        "    y_tr_raw = norm_to_raw(y_train_norm[idx_tr])\n",
        "    y_va_norm = y_train_norm[idx_val]\n",
        "\n",
        "    best_gamma = None\n",
        "    best_score = float('inf')\n",
        "\n",
        "    for gamma in gamma_grid:\n",
        "        S_tr = gravity_score_for_edges(tr_ids, float(gamma))\n",
        "        model = fit_loglinear_on_train(tr_ids, y_tr_raw, S_tr)\n",
        "\n",
        "        S_va = gravity_score_for_edges(va_ids, float(gamma))\n",
        "        pred_va_raw = predict_raw(va_ids, S_va, model)\n",
        "        pred_va_norm = raw_to_norm(pred_va_raw)\n",
        "\n",
        "        m = eval_metrics(y_va_norm, pred_va_norm)\n",
        "        score = m['MGEH']  # selection criterion\n",
        "        if score < best_score:\n",
        "            best_score = score\n",
        "            best_gamma = float(gamma)\n",
        "\n",
        "    return best_gamma, best_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b63b6a11",
      "metadata": {},
      "source": [
        "## 6) Outer CV runner (5-fold and spatial 9-fold)\n",
        "\n",
        "We evaluate:\n",
        "- 5-fold CV using your `utils.get_cv_split`\n",
        "- 9-fold spatial CV using your `utils.get_spatial_cv_split`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "db407bac",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare aligned y arrays\n",
        "kept_edges = all_edge_ids\n",
        "y_all_norm = np.array([float(edge_to_gt[e]) for e in kept_edges], dtype=np.float32)\n",
        "\n",
        "def run_gravity_cv(split_type: str, gamma_grid: np.ndarray):\n",
        "    rows = []\n",
        "\n",
        "    if split_type == 'kfold5':\n",
        "        fold_list = list(range(5))\n",
        "        split_fn = lambda fold: utils.get_cv_split(kept_edges, k=5, fold_idx=fold, seed=TRAINING['seed'])\n",
        "    elif split_type == 'spatial9':\n",
        "        fold_list = list(range(1, 10))\n",
        "        split_fn = lambda fold: utils.get_spatial_cv_split(kept_edges, fold_idx=fold)\n",
        "    else:\n",
        "        raise ValueError('split_type must be kfold5 or spatial9')\n",
        "\n",
        "    edge_to_pos = {e:i for i,e in enumerate(kept_edges)}\n",
        "\n",
        "    for fold in fold_list:\n",
        "        train_ids, test_ids = split_fn(fold)\n",
        "\n",
        "        tr_idx = np.array([edge_to_pos[e] for e in train_ids], dtype=np.int64)\n",
        "        te_idx = np.array([edge_to_pos[e] for e in test_ids], dtype=np.int64)\n",
        "\n",
        "        y_tr_norm = y_all_norm[tr_idx]\n",
        "        y_te_norm = y_all_norm[te_idx]\n",
        "\n",
        "        # --- pick gamma using inner split on training edges ---\n",
        "        best_gamma, inner_score = choose_gamma_inner(train_ids, y_tr_norm, gamma_grid)\n",
        "\n",
        "        # --- fit on full training fold with chosen gamma ---\n",
        "        S_tr = gravity_score_for_edges(train_ids, best_gamma)\n",
        "        y_tr_raw = norm_to_raw(y_tr_norm)\n",
        "        model = fit_loglinear_on_train(train_ids, y_tr_raw, S_tr)\n",
        "\n",
        "        # --- predict train/test ---\n",
        "        pred_tr_raw = predict_raw(train_ids, S_tr, model)\n",
        "        pred_tr_norm = raw_to_norm(pred_tr_raw)\n",
        "\n",
        "        S_te = gravity_score_for_edges(test_ids, best_gamma)\n",
        "        pred_te_raw = predict_raw(test_ids, S_te, model)\n",
        "        pred_te_norm = raw_to_norm(pred_te_raw)\n",
        "\n",
        "        m_tr = eval_metrics(y_tr_norm, pred_tr_norm)\n",
        "        m_te = eval_metrics(y_te_norm, pred_te_norm)\n",
        "\n",
        "        rows.append({\n",
        "            'split': split_type,\n",
        "            'fold': fold,\n",
        "            'model': 'GravityLogLinear',\n",
        "            'gamma': best_gamma,\n",
        "            'inner_val_MGEH': inner_score,\n",
        "            'train_MAE': m_tr['MAE'],\n",
        "            'train_MGEH': m_tr['MGEH'],\n",
        "            'train_R2': m_tr['R2'],\n",
        "            'test_MAE': m_te['MAE'],\n",
        "            'test_MGEH': m_te['MGEH'],\n",
        "            'test_R2': m_te['R2'],\n",
        "        })\n",
        "\n",
        "        print(f'[{split_type}] fold={fold} gamma={best_gamma:.3e} test_MGEH={m_te[\"MGEH\"]:.4f} test_R2={m_te[\"R2\"]:.4f}')\n",
        "\n",
        "    return pd.DataFrame(rows)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a85f3a5",
      "metadata": {},
      "source": [
        "## 7) Run gravity baseline\n",
        "\n",
        "Gamma grid: you can tune this. Since `t_OD` is in **seconds**, gamma is in 1/seconds.\n",
        "A reasonable starting grid is logspace from 1e-7 to 1e-3.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b546d68b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gamma grid: [1.00000000e-07 1.77827941e-07 3.16227766e-07 5.62341325e-07\n",
            " 1.00000000e-06 1.77827941e-06 3.16227766e-06 5.62341325e-06\n",
            " 1.00000000e-05 1.77827941e-05 3.16227766e-05 5.62341325e-05\n",
            " 1.00000000e-04 1.77827941e-04 3.16227766e-04 5.62341325e-04\n",
            " 1.00000000e-03]\n",
            "[kfold5] fold=0 gamma=1.000e-07 test_MGEH=65.8560 test_R2=0.5350\n",
            "[kfold5] fold=1 gamma=1.778e-04 test_MGEH=65.5835 test_R2=0.5648\n",
            "[kfold5] fold=2 gamma=3.162e-04 test_MGEH=65.7102 test_R2=0.5648\n",
            "[kfold5] fold=3 gamma=1.778e-04 test_MGEH=65.7839 test_R2=0.5360\n",
            "[kfold5] fold=4 gamma=1.000e-04 test_MGEH=65.0893 test_R2=0.5351\n",
            "[Spatial CV] Validation region: E12000001\n",
            "[Spatial CV] #val_edges = 143, #train_edges = 4945\n",
            "[spatial9] fold=1 gamma=1.000e-07 test_MGEH=66.2016 test_R2=0.1432\n",
            "[Spatial CV] Validation region: E12000002\n",
            "[Spatial CV] #val_edges = 608, #train_edges = 4480\n",
            "[spatial9] fold=2 gamma=1.000e-07 test_MGEH=72.2736 test_R2=0.4168\n",
            "[Spatial CV] Validation region: E12000003\n",
            "[Spatial CV] #val_edges = 580, #train_edges = 4508\n",
            "[spatial9] fold=3 gamma=1.778e-04 test_MGEH=55.5096 test_R2=0.7070\n",
            "[Spatial CV] Validation region: E12000004\n",
            "[Spatial CV] #val_edges = 426, #train_edges = 4662\n",
            "[spatial9] fold=4 gamma=1.778e-04 test_MGEH=60.3828 test_R2=0.5609\n",
            "[Spatial CV] Validation region: E12000005\n",
            "[Spatial CV] #val_edges = 480, #train_edges = 4608\n",
            "[spatial9] fold=5 gamma=1.000e-04 test_MGEH=67.4031 test_R2=0.5283\n",
            "[Spatial CV] Validation region: E12000006\n",
            "[Spatial CV] #val_edges = 667, #train_edges = 4421\n",
            "[spatial9] fold=6 gamma=1.000e-07 test_MGEH=63.3284 test_R2=0.6239\n",
            "[Spatial CV] Validation region: E12000007\n",
            "[Spatial CV] #val_edges = 85, #train_edges = 5003\n",
            "[spatial9] fold=7 gamma=1.778e-04 test_MGEH=71.5961 test_R2=0.5646\n",
            "[Spatial CV] Validation region: E12000008\n",
            "[Spatial CV] #val_edges = 957, #train_edges = 4131\n",
            "[spatial9] fold=8 gamma=1.000e-07 test_MGEH=67.5975 test_R2=0.5449\n",
            "[Spatial CV] Validation region: E12000009\n",
            "[Spatial CV] #val_edges = 392, #train_edges = 4696\n",
            "[spatial9] fold=9 gamma=1.778e-04 test_MGEH=77.0285 test_R2=0.2099\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>split</th>\n",
              "      <th>fold</th>\n",
              "      <th>model</th>\n",
              "      <th>gamma</th>\n",
              "      <th>inner_val_MGEH</th>\n",
              "      <th>train_MAE</th>\n",
              "      <th>train_MGEH</th>\n",
              "      <th>train_R2</th>\n",
              "      <th>test_MAE</th>\n",
              "      <th>test_MGEH</th>\n",
              "      <th>test_R2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>kfold5</td>\n",
              "      <td>0</td>\n",
              "      <td>GravityLogLinear</td>\n",
              "      <td>1.000000e-07</td>\n",
              "      <td>62.142414</td>\n",
              "      <td>9386.252930</td>\n",
              "      <td>65.242035</td>\n",
              "      <td>0.545796</td>\n",
              "      <td>9300.935547</td>\n",
              "      <td>65.856033</td>\n",
              "      <td>0.534991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kfold5</td>\n",
              "      <td>1</td>\n",
              "      <td>GravityLogLinear</td>\n",
              "      <td>1.778279e-04</td>\n",
              "      <td>62.138081</td>\n",
              "      <td>9386.032227</td>\n",
              "      <td>65.499939</td>\n",
              "      <td>0.543570</td>\n",
              "      <td>9381.845703</td>\n",
              "      <td>65.583466</td>\n",
              "      <td>0.564786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>kfold5</td>\n",
              "      <td>2</td>\n",
              "      <td>GravityLogLinear</td>\n",
              "      <td>3.162278e-04</td>\n",
              "      <td>63.098816</td>\n",
              "      <td>9438.019531</td>\n",
              "      <td>65.752205</td>\n",
              "      <td>0.549133</td>\n",
              "      <td>9322.496094</td>\n",
              "      <td>65.710228</td>\n",
              "      <td>0.564762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>kfold5</td>\n",
              "      <td>3</td>\n",
              "      <td>GravityLogLinear</td>\n",
              "      <td>1.778279e-04</td>\n",
              "      <td>65.616547</td>\n",
              "      <td>9362.286133</td>\n",
              "      <td>65.527046</td>\n",
              "      <td>0.549604</td>\n",
              "      <td>9546.560547</td>\n",
              "      <td>65.783852</td>\n",
              "      <td>0.535960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>kfold5</td>\n",
              "      <td>4</td>\n",
              "      <td>GravityLogLinear</td>\n",
              "      <td>1.000000e-04</td>\n",
              "      <td>66.180199</td>\n",
              "      <td>9297.393555</td>\n",
              "      <td>65.235550</td>\n",
              "      <td>0.555723</td>\n",
              "      <td>9441.710938</td>\n",
              "      <td>65.089348</td>\n",
              "      <td>0.535093</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    split  fold             model         gamma  inner_val_MGEH    train_MAE  \\\n",
              "0  kfold5     0  GravityLogLinear  1.000000e-07       62.142414  9386.252930   \n",
              "1  kfold5     1  GravityLogLinear  1.778279e-04       62.138081  9386.032227   \n",
              "2  kfold5     2  GravityLogLinear  3.162278e-04       63.098816  9438.019531   \n",
              "3  kfold5     3  GravityLogLinear  1.778279e-04       65.616547  9362.286133   \n",
              "4  kfold5     4  GravityLogLinear  1.000000e-04       66.180199  9297.393555   \n",
              "\n",
              "   train_MGEH  train_R2     test_MAE  test_MGEH   test_R2  \n",
              "0   65.242035  0.545796  9300.935547  65.856033  0.534991  \n",
              "1   65.499939  0.543570  9381.845703  65.583466  0.564786  \n",
              "2   65.752205  0.549133  9322.496094  65.710228  0.564762  \n",
              "3   65.527046  0.549604  9546.560547  65.783852  0.535960  \n",
              "4   65.235550  0.555723  9441.710938  65.089348  0.535093  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gamma_grid = np.logspace(-7, -3, 17)  # 17 values\n",
        "print('Gamma grid:', gamma_grid)\n",
        "\n",
        "df_k5 = run_gravity_cv('kfold5', gamma_grid)\n",
        "df_sp = run_gravity_cv('spatial9', gamma_grid)\n",
        "\n",
        "df_all = pd.concat([df_k5, df_sp], ignore_index=True)\n",
        "df_all.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f23eac2",
      "metadata": {},
      "source": [
        "## 8) Summaries (mean ± std across folds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "8f14ebfa",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>split</th>\n",
              "      <th>model</th>\n",
              "      <th>train_MAE_mean</th>\n",
              "      <th>train_MGEH_mean</th>\n",
              "      <th>train_R2_mean</th>\n",
              "      <th>test_MAE_mean</th>\n",
              "      <th>test_MGEH_mean</th>\n",
              "      <th>test_R2_mean</th>\n",
              "      <th>train_MAE_std</th>\n",
              "      <th>train_MGEH_std</th>\n",
              "      <th>train_R2_std</th>\n",
              "      <th>test_MAE_std</th>\n",
              "      <th>test_MGEH_std</th>\n",
              "      <th>test_R2_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>kfold5</td>\n",
              "      <td>GravityLogLinear</td>\n",
              "      <td>9373.996875</td>\n",
              "      <td>65.451355</td>\n",
              "      <td>0.548765</td>\n",
              "      <td>9398.709766</td>\n",
              "      <td>65.604585</td>\n",
              "      <td>0.547118</td>\n",
              "      <td>50.988163</td>\n",
              "      <td>0.217363</td>\n",
              "      <td>0.004611</td>\n",
              "      <td>99.198882</td>\n",
              "      <td>0.305139</td>\n",
              "      <td>0.016122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spatial9</td>\n",
              "      <td>GravityLogLinear</td>\n",
              "      <td>9362.868598</td>\n",
              "      <td>65.414610</td>\n",
              "      <td>0.544534</td>\n",
              "      <td>9565.117947</td>\n",
              "      <td>66.813452</td>\n",
              "      <td>0.477722</td>\n",
              "      <td>138.770902</td>\n",
              "      <td>0.649954</td>\n",
              "      <td>0.012172</td>\n",
              "      <td>1636.469666</td>\n",
              "      <td>6.515820</td>\n",
              "      <td>0.188032</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      split             model  train_MAE_mean  train_MGEH_mean  train_R2_mean  \\\n",
              "0    kfold5  GravityLogLinear     9373.996875        65.451355       0.548765   \n",
              "1  spatial9  GravityLogLinear     9362.868598        65.414610       0.544534   \n",
              "\n",
              "   test_MAE_mean  test_MGEH_mean  test_R2_mean  train_MAE_std  train_MGEH_std  \\\n",
              "0    9398.709766       65.604585      0.547118      50.988163        0.217363   \n",
              "1    9565.117947       66.813452      0.477722     138.770902        0.649954   \n",
              "\n",
              "   train_R2_std  test_MAE_std  test_MGEH_std  test_R2_std  \n",
              "0      0.004611     99.198882       0.305139     0.016122  \n",
              "1      0.012172   1636.469666       6.515820     0.188032  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def summarize(df: pd.DataFrame):\n",
        "    metrics = ['train_MAE','train_MGEH','train_R2','test_MAE','test_MGEH','test_R2']\n",
        "    g = df.groupby(['split','model'])[metrics]\n",
        "    mean = g.mean().add_suffix('_mean')\n",
        "    std  = g.std(ddof=1).add_suffix('_std')\n",
        "    out = pd.concat([mean, std], axis=1).reset_index()\n",
        "    return out\n",
        "\n",
        "summary = summarize(df_all)\n",
        "summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebbaa9cd",
      "metadata": {},
      "source": [
        "## 9) Save outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "edf99006",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved:\n",
            " - eval/baselines/baseline_gravity_all_folds.csv\n",
            " - eval/baselines/baseline_gravity_summary.csv\n"
          ]
        }
      ],
      "source": [
        "os.makedirs('eval/baselines', exist_ok=True)\n",
        "df_all.to_csv('eval/baselines/baseline_gravity_all_folds.csv', index=False)\n",
        "summary.to_csv('eval/baselines/baseline_gravity_summary.csv', index=False)\n",
        "print('Saved:')\n",
        "print(' - eval/baselines/baseline_gravity_all_folds.csv')\n",
        "print(' - eval/baselines/baseline_gravity_summary.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a5de0dd",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch_gpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
