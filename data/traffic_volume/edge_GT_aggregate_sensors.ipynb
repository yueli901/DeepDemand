{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da965a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network GeoJSON...\n",
      "Loading edge_to_sensor mapping...\n",
      "Loaded summary for 2017 (8913 sensors)\n",
      "Loaded summary for 2018 (8763 sensors)\n",
      "Loaded summary for 2019 (8794 sensors)\n",
      "Loaded summary for 2020 (9061 sensors)\n",
      "Loaded summary for 2021 (8930 sensors)\n",
      "Loaded summary for 2022 (9083 sensors)\n",
      "Loaded summary for 2023 (8862 sensors)\n",
      "Loaded summary for 2024 (8695 sensors)\n",
      "\n",
      "==== Multi-year GT build report ====\n",
      "Years included: [2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024]\n",
      "SENSOR_AGG (per-year sensor→edge): median\n",
      "YEAR_AGG   (across years):         median\n",
      "MIN_DAYS per sensor per year:      200\n",
      "Total edges in edge_to_sensor:     5782\n",
      " - Missing in GeoJSON network:     0\n",
      " - Excluded by highway:            47\n",
      " - No valid sensor across years:   868\n",
      " - GT == 0 removed:                0\n",
      "Final saved edges:                 4867\n",
      "Output GT   -> GT_total_pm_8years.json\n",
      "Output meta -> GT_total_pm_8years_meta.json\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# build_GT_multi_year_with_uncertainty.py\n",
    "#\n",
    "# Goal:\n",
    "#   Build multi-year edge-level GT (AADT-like total volume) and an uncertainty\n",
    "#   meta file using per-sensor, per-year summaries:\n",
    "#     - years: [2017, 2018, 2019, 2022, 2023, 2024]\n",
    "#     - per sensor & year: from traffic_volume_summary_<year>.json we use\n",
    "#         * \"Total Volume\": { \"mean\", \"sd\", \"num_valid_days\" }\n",
    "#   For each edge:\n",
    "#     1) For each year:\n",
    "#          - select sensors on that edge\n",
    "#          - filter by num_valid_days >= MIN_DAYS\n",
    "#          - remove sensors with mean <= 0 (zero GT never participates)\n",
    "#          - aggregate sensor-level \"mean\" to an edge-level yearly GT using\n",
    "#            SENSOR_AGG (\"mean\" or \"median\").\n",
    "#     2) Across years:\n",
    "#          - aggregate yearly GT values using YEAR_AGG (\"mean\" or \"median\")\n",
    "#          - remove edges with final GT == 0\n",
    "#     3) Compute a pooled daily SD over *all* sensors and years:\n",
    "#          - treat each sensor-year as (mean μ_sy, sd s_sy, n_sy days)\n",
    "#          - weighted overall mean μ* using n_sy\n",
    "#          - pooled variance:\n",
    "#              Var* = [ Σ (n_sy - 1) s_sy^2 + Σ n_sy (μ_sy - μ*)^2 ] / (Σ n_sy - 1)\n",
    "#          - SD* = sqrt(Var*)\n",
    "#          - CV* = SD* / GT_final\n",
    "#\n",
    "# Outputs:\n",
    "#   - GT_total_multi_year.json            (edge_id -> GT float)\n",
    "#   - GT_total_multi_year_meta.json      (edge_id -> dict with GT, per-year GT,\n",
    "#                                         counts, SD, CV, etc.)\n",
    "#\n",
    "# Notes:\n",
    "#   - All filtering by highway type and sensor-day count is done BEFORE\n",
    "#     any aggregation.\n",
    "#   - Sensor-year entries with mean <= 0 are ignored (GT=0 never used).\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "YEARS = [2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024]\n",
    "\n",
    "GEOJSON_PATH   = \"../highway_network/uk_driving_edges_simplified.geojson\"\n",
    "EDGE_TO_SENSOR = \"edge_to_sensor.json\"\n",
    "\n",
    "OUT_GT_JSON   = \"GT_car_pm_8years.json\"\n",
    "OUT_META_JSON = \"GT_car_pm_8years_meta.json\"\n",
    "\n",
    "# Min number of complete days required per sensor per year\n",
    "MIN_DAYS = 200\n",
    "CAR_TYPE = \"0 - 520 cm\"\n",
    "SUMMARY_PATH = \"weekday_am_pm/evening_peak_weekdays\"\n",
    "\n",
    "# Highway types to keep\n",
    "ALLOWED = {\"motorway\", \"trunk\", \"motorway_link\", \"trunk_link\"}\n",
    "\n",
    "# Aggregation choices:\n",
    "#   - SENSOR_AGG: how to aggregate multiple sensors on the same edge in a given year\n",
    "#   - YEAR_AGG:   how to aggregate multiple yearly values per edge\n",
    "# Options: \"mean\" or \"median\"\n",
    "SENSOR_AGG = \"median\"   # e.g. \"mean\" or \"median\"\n",
    "YEAR_AGG   = \"median\"   # e.g. \"mean\" or \"median\"\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Small helper for aggregation\n",
    "# -----------------------------\n",
    "def aggregate(vals, mode: str):\n",
    "    \"\"\"Aggregate a list of floats using 'mean' or 'median'. Return None if empty.\"\"\"\n",
    "    if not vals:\n",
    "        return None\n",
    "    arr = np.asarray(vals, dtype=float)\n",
    "    if mode == \"mean\":\n",
    "        return float(np.mean(arr))\n",
    "    elif mode == \"median\":\n",
    "        return float(np.median(arr))\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown aggregation mode: {mode}\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Load network\n",
    "# -----------------------------\n",
    "print(\"Loading network GeoJSON...\")\n",
    "# gdf = gpd.read_file(GEOJSON_PATH)\n",
    "\n",
    "gdf[\"edge_id\"] = (\n",
    "    gdf[\"u\"].astype(str) + \"_\" +\n",
    "    gdf[\"v\"].astype(str) + \"_\" +\n",
    "    gdf[\"key\"].astype(str)\n",
    ")\n",
    "gdf[\"highway\"] = gdf[\"highway\"].astype(str).str.lower()\n",
    "edge_to_highway = dict(zip(gdf[\"edge_id\"], gdf[\"highway\"]))\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Load edge-to-sensor mapping\n",
    "# -----------------------------\n",
    "print(\"Loading edge_to_sensor mapping...\")\n",
    "with open(EDGE_TO_SENSOR, \"r\") as f:\n",
    "    edge_to_sensor = json.load(f)\n",
    "\n",
    "n_total_edges_map = len(edge_to_sensor)\n",
    "\n",
    "# Audit counters\n",
    "n_missing_in_network = 0\n",
    "n_excluded_highway   = 0\n",
    "n_no_valid_sensor    = 0\n",
    "n_zero_gt_removed    = 0\n",
    "\n",
    "# -----------------------------\n",
    "# Load all year summaries\n",
    "# -----------------------------\n",
    "summary_by_year = {}\n",
    "\n",
    "for yr in YEARS:\n",
    "    path = SUMMARY_PATH + f\"_{yr}.json\"\n",
    "    try:\n",
    "        with open(path, \"r\") as f:\n",
    "            summary_by_year[yr] = json.load(f)\n",
    "        print(f\"Loaded summary for {yr} ({len(summary_by_year[yr])} sensors)\")\n",
    "    except FileNotFoundError:\n",
    "        raise RuntimeError(f\"Missing file: {path}\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Main build: GT + meta\n",
    "# -----------------------------\n",
    "gt_out   = {}  # edge_id -> final GT\n",
    "meta_out = {}  # edge_id -> meta dict\n",
    "\n",
    "for edge_id, sensor_ids in edge_to_sensor.items():\n",
    "\n",
    "    # 1) Ensure edge belongs to network\n",
    "    hwy = edge_to_highway.get(edge_id)\n",
    "    if hwy is None:\n",
    "        n_missing_in_network += 1\n",
    "        continue\n",
    "\n",
    "    # 2) Highway filter\n",
    "    if hwy not in ALLOWED:\n",
    "        n_excluded_highway += 1\n",
    "        continue\n",
    "\n",
    "    # per-edge containers\n",
    "    gt_per_year             = {}  # year -> GT_year\n",
    "    n_sensors_per_year      = {}  # year -> #sensors used\n",
    "    n_days_per_year         = {}  # year -> total days across used sensors\n",
    "    sensor_year_means   = []      # list of μ_sy over all sensors & years\n",
    "    sensor_year_sds     = []      # list of s_sy\n",
    "    sensor_year_ndays   = []      # list of n_sy\n",
    "\n",
    "    # 3) Compute year-level GTs and collect sensor-year stats\n",
    "    for yr in YEARS:\n",
    "        ts = summary_by_year[yr]\n",
    "\n",
    "        stats_list = []  # [(mean, sd, n_days), ...] for this edge & year\n",
    "        for sid in sensor_ids:\n",
    "            s = str(sid)\n",
    "            rec = ts.get(s)\n",
    "            if not rec:\n",
    "                continue\n",
    "\n",
    "            band = rec.get(CAR_TYPE)\n",
    "            if not band:\n",
    "                continue\n",
    "\n",
    "            n_days = band.get(\"num_valid_days\", 0)\n",
    "            if n_days < MIN_DAYS:\n",
    "                continue\n",
    "\n",
    "            m = band.get(\"mean\")\n",
    "            sd = band.get(\"sd\")\n",
    "\n",
    "            # remove sensor-year entries with non-positive mean (GT=0 or negative)\n",
    "            if m is None or m <= 0:\n",
    "                continue\n",
    "\n",
    "            # sd can be None (should not be, but be safe)\n",
    "            if sd is None:\n",
    "                continue\n",
    "\n",
    "            stats_list.append((float(m), float(sd), int(n_days)))\n",
    "\n",
    "        if not stats_list:\n",
    "            # no valid sensor for this edge in this year\n",
    "            continue\n",
    "\n",
    "        # Sensor-level means for this year (for GT aggregation)\n",
    "        sensor_means_this_year = [m for (m, sd, nd) in stats_list]\n",
    "        gt_year = aggregate(sensor_means_this_year, SENSOR_AGG)\n",
    "\n",
    "        # ignore year-level GT if it ends up <= 0 (shouldn't happen if we filtered m>0)\n",
    "        if gt_year is None or gt_year <= 0:\n",
    "            continue\n",
    "\n",
    "        gt_per_year[yr]        = float(gt_year)\n",
    "        n_sensors_per_year[yr] = len(stats_list)\n",
    "        n_days_per_year[yr]    = int(sum(nd for (_, _, nd) in stats_list))\n",
    "\n",
    "        # append sensor-year stats to global lists for pooled variance\n",
    "        for (m, sd, nd) in stats_list:\n",
    "            sensor_year_means.append(m)\n",
    "            sensor_year_sds.append(sd)\n",
    "            sensor_year_ndays.append(nd)\n",
    "\n",
    "    # If no valid year for this edge, we drop it\n",
    "    if not gt_per_year:\n",
    "        n_no_valid_sensor += 1\n",
    "        continue\n",
    "\n",
    "    # 4) Final GT = YEAR_AGG across all available years\n",
    "    final_gt = aggregate(list(gt_per_year.values()), YEAR_AGG)\n",
    "\n",
    "    if final_gt is None or final_gt == 0.0:\n",
    "        n_zero_gt_removed += 1\n",
    "        continue\n",
    "\n",
    "    # 5) Pooled daily variance across all sensors and years\n",
    "    sd_daily = None\n",
    "    cv_daily = None\n",
    "    n_days_total = int(sum(sensor_year_ndays)) if sensor_year_ndays else 0\n",
    "\n",
    "    if sensor_year_ndays and n_days_total > 1:\n",
    "        # Weighted overall mean μ* = Σ n_sy μ_sy / Σ n_sy\n",
    "        num_mu = 0.0\n",
    "        for n_sy, mu_sy in zip(sensor_year_ndays, sensor_year_means):\n",
    "            num_mu += n_sy * mu_sy\n",
    "        mu_star = num_mu / n_days_total\n",
    "\n",
    "        # Pooled variance numerator:\n",
    "        #   Σ (n_sy - 1) s_sy^2  +  Σ n_sy (μ_sy - μ*)^2\n",
    "        num_var = 0.0\n",
    "        for n_sy, mu_sy, sd_sy in zip(sensor_year_ndays, sensor_year_means, sensor_year_sds):\n",
    "            if n_sy <= 1:\n",
    "                continue\n",
    "            num_var += (n_sy - 1) * (sd_sy ** 2)\n",
    "            num_var += n_sy * ((mu_sy - mu_star) ** 2)\n",
    "\n",
    "        if num_var >= 0 and n_days_total > 1:\n",
    "            var_daily = num_var / (n_days_total - 1)\n",
    "            if var_daily < 0:\n",
    "                var_daily = 0.0\n",
    "            sd_daily = float(np.sqrt(var_daily))\n",
    "            if final_gt > 0:\n",
    "                cv_daily = float(sd_daily / final_gt)\n",
    "\n",
    "    # 6) Store outputs\n",
    "    gt_out[edge_id] = float(final_gt)\n",
    "\n",
    "    meta_out[edge_id] = {\n",
    "        \"gt\": float(final_gt),\n",
    "        \"years_used\": sorted(int(y) for y in gt_per_year.keys()),\n",
    "        \"gt_per_year\": {str(y): float(v) for y, v in gt_per_year.items()},\n",
    "        \"n_sensors_per_year\": {str(y): int(n) for y, n in n_sensors_per_year.items()},\n",
    "        \"n_days_per_year\": {str(y): int(n) for y, n in n_days_per_year.items()},\n",
    "        \"n_days_total\": int(n_days_total),\n",
    "        \"sd_daily\": sd_daily,\n",
    "        \"cv_daily\": cv_daily,\n",
    "        \"sensor_agg\": SENSOR_AGG,\n",
    "        \"year_agg\": YEAR_AGG,\n",
    "        \"min_days\": MIN_DAYS,\n",
    "        \"highway_type\": hwy,\n",
    "    }\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Save result\n",
    "# -----------------------------\n",
    "with open(OUT_GT_JSON, \"w\") as f:\n",
    "    json.dump(gt_out, f, indent=2)\n",
    "\n",
    "with open(OUT_META_JSON, \"w\") as f:\n",
    "    json.dump(meta_out, f, indent=2)\n",
    "\n",
    "# -----------------------------\n",
    "# Report\n",
    "# -----------------------------\n",
    "print(\"\\n==== Multi-year GT build report ====\")\n",
    "print(f\"Years included: {YEARS}\")\n",
    "print(f\"SENSOR_AGG (per-year sensor→edge): {SENSOR_AGG}\")\n",
    "print(f\"YEAR_AGG   (across years):         {YEAR_AGG}\")\n",
    "print(f\"MIN_DAYS per sensor per year:      {MIN_DAYS}\")\n",
    "print(f\"Total edges in edge_to_sensor:     {n_total_edges_map}\")\n",
    "print(f\" - Missing in GeoJSON network:     {n_missing_in_network}\")\n",
    "print(f\" - Excluded by highway:            {n_excluded_highway}\")\n",
    "print(f\" - No valid sensor across years:   {n_no_valid_sensor}\")\n",
    "print(f\" - GT == 0 removed:                {n_zero_gt_removed}\")\n",
    "print(f\"Final saved edges:                 {len(gt_out)}\")\n",
    "print(f\"Output GT   -> {OUT_GT_JSON}\")\n",
    "print(f\"Output meta -> {OUT_META_JSON}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8439cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AM keys not in base ===\n",
      "\n",
      "=== PM keys not in base ===\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------------\n",
    "# File paths\n",
    "# -------------------------\n",
    "DIR = Path(\".\")\n",
    "\n",
    "base_file = DIR / \"GT_AADT_8years.json\"\n",
    "am_file   = DIR / \"GT_total_am_8years.json\"\n",
    "pm_file   = DIR / \"GT_total_pm_8years.json\"\n",
    "\n",
    "# -------------------------\n",
    "# Load json keys\n",
    "# -------------------------\n",
    "with open(base_file, \"r\") as f:\n",
    "    base = set(json.load(f).keys())\n",
    "\n",
    "with open(am_file, \"r\") as f:\n",
    "    am = set(json.load(f).keys())\n",
    "\n",
    "with open(pm_file, \"r\") as f:\n",
    "    pm = set(json.load(f).keys())\n",
    "\n",
    "# -------------------------\n",
    "# Compare\n",
    "# -------------------------\n",
    "missing_am = sorted(am - base)\n",
    "missing_pm = sorted(pm - base)\n",
    "\n",
    "print(\"=== AM keys not in base ===\")\n",
    "for k in missing_am:\n",
    "    print(k)\n",
    "\n",
    "print(\"\\n=== PM keys not in base ===\")\n",
    "for k in missing_pm:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c995965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
