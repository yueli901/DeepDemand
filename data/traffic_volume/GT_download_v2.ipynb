{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f093e96-ad5d-4ec4-be35-2a911dbb19f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import requests\n",
    "import warnings\n",
    "\n",
    "df = pd.read_csv('sensor_quality_2015-2024.csv')\n",
    "year = '2015'\n",
    "start = f'{year}-01-01 00:14:00'\n",
    "end = f'{year}-12-31 23:59:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eca15cd5-f6e4-4ec8-b7ed-4bd5dd860cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a DataFrame with a fixed set of timestamps for every 15 minutes of y, considering UK DST adjustments\n",
    "def generate_fixed_timestamps(start, end):\n",
    "    # Create range for the whole year with 15-minute intervals\n",
    "    dt_range = pd.date_range(start=start, end=end, freq='15min')\n",
    "\n",
    "    fixed_df = pd.DataFrame({'Timestamp': dt_range})\n",
    "    return fixed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "862149eb-076d-4718-9081-6f94cbc9db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch data for a single site\n",
    "def fetch_data_for_site(site_id):\n",
    "    page = 1\n",
    "    while True:\n",
    "        url = f\"{base_url}?sites={site_id}&page={page}&page_size=5000\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            if page > 1:\n",
    "                break\n",
    "            else:\n",
    "                print(f\"Data download stopped at page {page-1} for site {site_id}\")\n",
    "                break\n",
    "        \n",
    "        data = response.json()\n",
    "        if not data['Rows']:\n",
    "            break\n",
    "        \n",
    "        result = pd.DataFrame(data['Rows'])\n",
    "\n",
    "        yield result\n",
    "        page += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1185c4d8-1497-4115-8d56-7d171f38236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "log_file = f'{year}_data_processing.log'\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=log_file,\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Base URL for API\n",
    "base_url = f'https://webtris.nationalhighways.co.uk/api/v1.0/reports/{start[8:10]+start[5:7]+start[0:4]}/to/{end[8:10]+end[5:7]+end[0:4]}/daily'\n",
    "\n",
    "# Create the fixed timestamp DataFrame\n",
    "fixed_timestamps_df = generate_fixed_timestamps(start, end)\n",
    "t = len(fixed_timestamps_df)\n",
    "\n",
    "# Directory for saving CSV files\n",
    "output_dir = f'./{year}/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Filter the list of valid sensors based on data quality\n",
    "quality_col = f'{year}_data_quality'\n",
    "valid_sensors = df[df[quality_col] > 0]['Id'].tolist()\n",
    "logging.info(f\"Filtered {len(valid_sensors)} valid sensors based on quality > 0.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89082e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through valid sensor IDs and fetch data\n",
    "for site_id in tqdm(valid_sensors, desc=\"Processing Sensors\"):\n",
    "    site_id = str(site_id)\n",
    "\n",
    "    # Check if CSV already exists\n",
    "    csv_path = os.path.join(output_dir, f'{site_id}.csv')\n",
    "    if os.path.exists(csv_path):\n",
    "        logging.info(f'{csv_path} already exists. Skipping.')\n",
    "        continue\n",
    "\n",
    "    site_data_frames = []\n",
    "    for df_page in fetch_data_for_site(site_id):\n",
    "        df_page = df_page[['Site Name', 'Report Date', 'Time Period Ending', \"0 - 520 cm\", \"521 - 660 cm\", \"661 - 1160 cm\", \"1160+ cm\", 'Total Volume', 'Avg mph']]\n",
    "        site_data_frames.append(df_page)\n",
    "\n",
    "    if site_data_frames:  # Only process if we have data\n",
    "        df = pd.concat(site_data_frames, ignore_index=True)\n",
    "        df['Avg mph'] = pd.to_numeric(df['Avg mph'], errors='coerce')\n",
    "        df['0 - 520 cm'] = pd.to_numeric(df['0 - 520 cm'], errors='coerce')        \n",
    "        df['521 - 660 cm'] = pd.to_numeric(df['521 - 660 cm'], errors='coerce')\n",
    "        df['661 - 1160 cm'] = pd.to_numeric(df['661 - 1160 cm'], errors='coerce')\n",
    "        df['1160+ cm'] = pd.to_numeric(df['1160+ cm'], errors='coerce')\n",
    "        df['Total Volume'] = pd.to_numeric(df['Total Volume'], errors='coerce')\n",
    "        \n",
    "        # Combine 'Report Date' and 'Time Period Ending' into a full datetime\n",
    "        df['Timestamp'] = pd.to_datetime(df['Report Date'].str.slice(0, 10) + ' ' + df['Time Period Ending'].str.slice(0, 5))\n",
    "\n",
    "        # Handle duplicates\n",
    "        duplicate_rows = df.duplicated(subset='Timestamp', keep=False)\n",
    "        duplicate_df = df[duplicate_rows]\n",
    "        \n",
    "        if not duplicate_df.empty:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "                averaged_df = duplicate_df.groupby('Timestamp').agg({\n",
    "                    '0 - 520 cm': lambda x: np.nanmean(x.astype(float)),\n",
    "                    '521 - 660 cm': lambda x: np.nanmean(x.astype(float)),\n",
    "                    '661 - 1160 cm': lambda x: np.nanmean(x.astype(float)),\n",
    "                    '1160+ cm': lambda x: np.nanmean(x.astype(float)),\n",
    "                    'Total Volume': lambda x: np.nanmean(x.astype(float)),\n",
    "                    'Avg mph': lambda x: np.nanmean(x.astype(float)),\n",
    "                    'Site Name': 'first',  # Keep the first site name\n",
    "                    'Report Date': 'first',  # Keep the first report date\n",
    "                    'Time Period Ending': 'first'  # Keep the first time period ending\n",
    "                }).reset_index()\n",
    "            \n",
    "            df = df[~duplicate_rows]\n",
    "            df = pd.concat([df, averaged_df], ignore_index=True)\n",
    "        \n",
    "        # Sort by timestamp and merge with fixed timestamps\n",
    "        df.sort_values(by='Timestamp', inplace=True)\n",
    "        merged_df = pd.merge(fixed_timestamps_df, df, on='Timestamp', how='left')\n",
    "        merged_df.drop(columns=['Report Date', 'Time Period Ending', 'Site Name'], inplace=True)\n",
    "\n",
    "        # clean: Impute Avg mph = 0 (when Total Volume = 0) with the closest previous non-zero Avg mph reading\n",
    "        prev_nonzero_speed = np.nan  # Initialize with np.nan\n",
    "        for idx, row in merged_df.iterrows():\n",
    "            if row['Total Volume'] == 0:  # If Total Volume is 0\n",
    "                if not np.isnan(prev_nonzero_speed):\n",
    "                    merged_df.at[idx, 'Avg mph'] = prev_nonzero_speed\n",
    "            else:\n",
    "                # Update the previous non-zero speed only if 'Avg mph' is not NaN\n",
    "                if not pd.isna(row['Avg mph']):\n",
    "                    prev_nonzero_speed = row['Avg mph']\n",
    "\n",
    "        # Write to CSV\n",
    "        merged_df.to_csv(csv_path, index=False)\n",
    "        logging.info(f'{csv_path} has been saved.')\n",
    "    else:\n",
    "        logging.info(f'Sensor {site_id} has no valid data or is inactive.')\n",
    "\n",
    "logging.info(\"Data processing completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
