{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0686da49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# === File paths ===\n",
    "EMPLOYMENT_TOTAL = 'processed_employment_data/employment_2022_employment.csv'\n",
    "EMPLOYMENT_FULL = 'processed_employment_data/employment_2022_full_time_employees.csv'\n",
    "EMPLOYMENT_PART = 'processed_employment_data/employment_2022_part_time_employees.csv'\n",
    "LSOA_LOOKUP = 'LSOA_(2011)_to_LSOA_(2021)_to_Local_Authority_District_(2022)_Exact_Fit_Lookup_for_EW_(V3).csv'\n",
    "POPULATION_JSON = '../population/population_2022_LSOA21.json'\n",
    "OUTPUT_FILE = 'employment_2022_LSOA21.json'\n",
    "\n",
    "# === Load population 2022 for proportional split ===\n",
    "with open(POPULATION_JSON, 'r') as f:\n",
    "    population_data = json.load(f)\n",
    "pop_2022 = {k: v['population_lv1'][0] for k, v in population_data.items()}\n",
    "\n",
    "# === Load LSOA lookup table ===\n",
    "lookup_df = pd.read_csv(LSOA_LOOKUP)\n",
    "lsoa11_to_21 = defaultdict(list)\n",
    "lsoa21_from_11 = defaultdict(list)\n",
    "for _, row in lookup_df.iterrows():\n",
    "    lsoa11 = row['LSOA11CD']\n",
    "    lsoa21 = row['LSOA21CD']\n",
    "    lsoa11_to_21[lsoa11].append(lsoa21)\n",
    "    lsoa21_from_11[lsoa21].append(lsoa11)\n",
    "\n",
    "# === Helper to load employment data ===\n",
    "def load_employment_csv(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.drop(columns=[df.columns[0]])  # drop first column\n",
    "    df = df.rename(columns={df.columns[0]: \"mnemonic\"})  # rename second column to \"mnemonic\"\n",
    "    df = df.set_index(\"mnemonic\")\n",
    "    return df\n",
    "\n",
    "total_df = load_employment_csv(EMPLOYMENT_TOTAL)\n",
    "full_df = load_employment_csv(EMPLOYMENT_FULL)\n",
    "part_df = load_employment_csv(EMPLOYMENT_PART)\n",
    "assert total_df.shape[1] == 18  # columns are sectors\n",
    "\n",
    "# === Collect raw data by LSOA11 ===\n",
    "raw_employment = {}\n",
    "\n",
    "for lsoa11 in total_df.index:\n",
    "    total_sectors = total_df.loc[lsoa11].fillna(0).astype(int).tolist()\n",
    "    full_sectors = full_df.loc[lsoa11].fillna(0).astype(int).tolist()# if lsoa11 in full_df.index else [0]*18\n",
    "    part_sectors = part_df.loc[lsoa11].fillna(0).astype(int).tolist()# if lsoa11 in part_df.index else [0]*18\n",
    "\n",
    "    total_all = sum(total_sectors)\n",
    "    full_all = sum(full_sectors)\n",
    "    part_all = sum(part_sectors)\n",
    "\n",
    "    lv2 = [total_all, full_all, part_all] + total_sectors\n",
    "    lv3 = lv2 + full_sectors + part_sectors\n",
    "    raw_employment[lsoa11] = {\n",
    "        'employment_lv1': [total_all],\n",
    "        'employment_lv2': lv2,\n",
    "        'employment_lv3': lv3\n",
    "    }\n",
    "    \n",
    "# === Save result ===\n",
    "with open('employment_2022_LSOA11.json', 'w') as f:\n",
    "    json.dump(raw_employment, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8d42189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual assignments      : 6\n",
      "1-to-1 direct copies    : 33647\n",
      "1-to-N splits           : 861\n",
      "N-to-1 merges           : 119\n",
      "Unmatched/skipped       : 0\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "final_employment = defaultdict(lambda: {'employment_lv1': [0], 'employment_lv2': [0]*21, 'employment_lv3': [0]*57})\n",
    "\n",
    "# === Manual override for known 2 <-> 2 mappings ===\n",
    "manual_map = {\n",
    "    \"E01008187\": \"E01035624\",\n",
    "    \"E01027506\": \"E01035637\",\n",
    "    \"E01023508\": \"E01035609\",\n",
    "    \"E01023768\": \"E01035582\",\n",
    "    \"E01023964\": \"E01035608\",\n",
    "    \"E01023679\": \"E01035581\",\n",
    "}\n",
    "\n",
    "# === Counters\n",
    "counter_1to1 = 0\n",
    "counter_1toN = 0\n",
    "counter_Nto1 = 0\n",
    "counter_manual = 0\n",
    "counter_skipped = 0\n",
    "\n",
    "used_in_merge = set()\n",
    "\n",
    "for lsoa11, values in raw_employment.items():\n",
    "    # Manual override\n",
    "    if lsoa11 in manual_map:\n",
    "        lsoa21 = manual_map[lsoa11]\n",
    "        final_employment[lsoa21] = values\n",
    "        counter_manual += 1\n",
    "        continue\n",
    "\n",
    "    lsoa21_list = lsoa11_to_21.get(lsoa11, [])\n",
    "\n",
    "    # Exact 1:1 match\n",
    "    if len(lsoa21_list) == 1 and lsoa21_list[0] == lsoa11:\n",
    "        lsoa21 = lsoa21_list[0]\n",
    "        final_employment[lsoa21] = values\n",
    "        counter_1to1 += 1\n",
    "\n",
    "    # One-to-many split\n",
    "    elif len(lsoa21_list) > 1:\n",
    "        pops = [pop_2022.get(l21, 0) for l21 in lsoa21_list]\n",
    "        total_pop = sum(pops)\n",
    "\n",
    "        if total_pop == 0:\n",
    "            print(f\"[WARNING] Skipping {lsoa11} split to {lsoa21_list} — no population data.\")\n",
    "            counter_skipped += 1\n",
    "            continue\n",
    "\n",
    "        if any(p == 0 for p in pops):\n",
    "            print(f\"[WARNING] Some LSOA21s missing population in split: {lsoa11} → {lsoa21_list}\")\n",
    "\n",
    "        for l21 in lsoa21_list:\n",
    "            proportion = pop_2022.get(l21, 0) / total_pop\n",
    "            final_employment[l21]['employment_lv1'] = [int(round(v * proportion)) for v in values['employment_lv1']]\n",
    "            final_employment[l21]['employment_lv2'] = [int(round(v * proportion)) for v in values['employment_lv2']]\n",
    "            final_employment[l21]['employment_lv3'] = [int(round(v * proportion)) for v in values['employment_lv3']]\n",
    "        counter_1toN += 1\n",
    "\n",
    "    # Many-to-one merge\n",
    "    else:\n",
    "        # Determine if this LSOA11 is part of a many-to-one merge group\n",
    "        for lsoa21, lsoa11_group in lsoa21_from_11.items():\n",
    "            if lsoa11 in lsoa11_group:\n",
    "                if len(lsoa11_group) > 1:\n",
    "                    used_in_merge.add(lsoa21)\n",
    "                    final_employment[lsoa21]['employment_lv1'] = [x + y for x, y in zip(final_employment[lsoa21]['employment_lv1'], values['employment_lv1'])]\n",
    "                    final_employment[lsoa21]['employment_lv2'] = [x + y for x, y in zip(final_employment[lsoa21]['employment_lv2'], values['employment_lv2'])]\n",
    "                    final_employment[lsoa21]['employment_lv3'] = [x + y for x, y in zip(final_employment[lsoa21]['employment_lv3'], values['employment_lv3'])]\n",
    "                    counter_Nto1 += 1\n",
    "                break\n",
    "        else:\n",
    "            print(f\"[WARNING] {lsoa11} not found in any valid transformation group.\")\n",
    "            counter_skipped += 1\n",
    "\n",
    "# === Summary ===\n",
    "print(f\"Manual assignments      : {counter_manual}\")\n",
    "print(f\"1-to-1 direct copies    : {counter_1to1}\")\n",
    "print(f\"1-to-N splits           : {counter_1toN}\")\n",
    "print(f\"N-to-1 merges           : {len(used_in_merge)}\")\n",
    "print(f\"Unmatched/skipped       : {counter_skipped}\")\n",
    "\n",
    "# === Save to file ===\n",
    "with open(OUTPUT_FILE, 'w') as f:\n",
    "    json.dump(final_employment, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19debee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved normalized JSON with 35672 LSOA21 entries → lsoa21_employment_2022_normalized.json\n",
      "Lengths: lv1=1, lv2=21, lv3=57\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# ---- Paths ----\n",
    "INPUT_JSON  = 'lsoa21_employment_2022.json'                 # created by your script\n",
    "OUTPUT_JSON = 'lsoa21_employment_2022_normalized.json'      # same structure, min–max normalized\n",
    "\n",
    "# ---- Load ----\n",
    "with open(INPUT_JSON, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Sanity: infer lengths from first record\n",
    "first_key = next(iter(data))\n",
    "lv1_len = len(data[first_key]['employment_lv1'])\n",
    "lv2_len = len(data[first_key]['employment_lv2'])\n",
    "lv3_len = len(data[first_key]['employment_lv3'])\n",
    "\n",
    "# Build matrices (consistent key order)\n",
    "keys = list(data.keys())\n",
    "mat_lv1 = np.array([data[k]['employment_lv1'] for k in keys], dtype=float)  # (N, 1)\n",
    "mat_lv2 = np.array([data[k]['employment_lv2'] for k in keys], dtype=float)  # (N, 21)\n",
    "mat_lv3 = np.array([data[k]['employment_lv3'] for k in keys], dtype=float)  # (N, 57)\n",
    "\n",
    "# def minmax(arr: np.ndarray) -> np.ndarray:\n",
    "#     lo = np.nanmin(arr, axis=0)\n",
    "#     hi = np.nanmax(arr, axis=0)\n",
    "#     rng = np.where((hi - lo) == 0.0, 1.0, (hi - lo))\n",
    "#     return (arr - lo) / rng\n",
    "\n",
    "# # ---- Normalize per level (column-wise) ----\n",
    "# norm_lv1 = minmax(mat_lv1)\n",
    "# norm_lv2 = minmax(mat_lv2)\n",
    "# norm_lv3 = minmax(mat_lv3)\n",
    "\n",
    "def zscore(arr: np.ndarray) -> np.ndarray:\n",
    "    mean = np.nanmean(arr, axis=0)\n",
    "    std = np.nanstd(arr, axis=0)\n",
    "    std = np.where(std == 0.0, 1.0, std)  # avoid divide-by-zero\n",
    "    return (arr - mean) / std\n",
    "\n",
    "# ---- Normalize per level (column-wise) ----\n",
    "norm_lv1 = zscore(mat_lv1)\n",
    "norm_lv2 = zscore(mat_lv2)\n",
    "norm_lv3 = zscore(mat_lv3)\n",
    "\n",
    "# ---- Write back with same format ----\n",
    "out = {}\n",
    "for i, k in enumerate(keys):\n",
    "    out[k] = {\n",
    "        'lv1': norm_lv1[i].tolist(),\n",
    "        'lv2': norm_lv2[i].tolist(),\n",
    "        'lv3': norm_lv3[i].tolist(),\n",
    "    }\n",
    "\n",
    "with open(OUTPUT_JSON, 'w') as f:\n",
    "    json.dump(out, f, indent=2)\n",
    "\n",
    "print(f\"Saved normalized JSON with {len(out)} LSOA21 entries → {OUTPUT_JSON}\")\n",
    "print(f\"Lengths: lv1={lv1_len}, lv2={lv2_len}, lv3={lv3_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8421a919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
