{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbee6202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "# set the notebook's CWD to your repo root\n",
    "%cd D:/deepdemand\n",
    "ROOT = Path.cwd().parents[0]   # go up one level\n",
    "sys.path.insert(0, str(ROOT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c372bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2040"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74de4d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from config import DATA, TRAINING\n",
    "from model.deepdemand import DeepDemand\n",
    "from model.dataloader import load_gt, load_json, get_lsoa_vector\n",
    "import model.utils as utils\n",
    "\n",
    "\n",
    "def set_seeds(seed: int):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "def build_feature_bank():\n",
    "    \"\"\"\n",
    "    Rebuild the same LSOA feature bank used in training.\n",
    "    Honors optional PCA in TRAINING config (same as your trainer).\n",
    "    \"\"\"\n",
    "    lsoa_json = load_json(\"data/node_features/lsoa21_features_normalized_2040.json\")\n",
    "    node_to_lsoa = load_json(\"data/node_features/node_to_lsoa.json\")\n",
    "\n",
    "    lsoa_codes = sorted(lsoa_json.keys())\n",
    "    rows = [get_lsoa_vector(lsoa_json[c]).cpu().numpy() for c in lsoa_codes]\n",
    "    X = np.vstack(rows).astype(np.float32)\n",
    "\n",
    "    feature_bank = {}\n",
    "\n",
    "    if TRAINING.get(\"pca\", False):\n",
    "        # Recompute PCA (same seed + same data → same result); or load from .npz if you prefer.\n",
    "        k = int(TRAINING.get(\"pca_components\", 32))\n",
    "        Xp, mean, comps = utils.pca_project(X, k)\n",
    "        for i, code in enumerate(lsoa_codes):\n",
    "            feature_bank[code] = torch.from_numpy(Xp[i])\n",
    "    else:\n",
    "        for i, code in enumerate(lsoa_codes):\n",
    "            feature_bank[code] = torch.from_numpy(X[i])\n",
    "\n",
    "    return feature_bank, node_to_lsoa\n",
    "\n",
    "\n",
    "def load_model(checkpoint_path: str, device: torch.device) -> DeepDemand:\n",
    "    feature_bank, node_to_lsoa = build_feature_bank()\n",
    "    model = DeepDemand(feature_bank=feature_bank, node_to_lsoa=node_to_lsoa).to(device)\n",
    "\n",
    "    if not os.path.isfile(checkpoint_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint not found: {checkpoint_path}\")\n",
    "\n",
    "    state = torch.load(checkpoint_path, map_location=device, weights_only=True)\n",
    "    model.load_state_dict(state)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "@torch.no_grad()\n",
    "def infer_on_edges(model: DeepDemand, edge_ids, edge_to_gt, scaler, device: torch.device):\n",
    "    preds, gts = [], []\n",
    "    for eid in edge_ids:\n",
    "        gt = edge_to_gt[eid]\n",
    "        y_hat = model(eid)\n",
    "        if y_hat is None or y_hat.numel() == 0:\n",
    "            continue\n",
    "\n",
    "        # Move to CPU numpy\n",
    "        y_hat = y_hat.detach().cpu().numpy().item()\n",
    "        gt = float(gt)\n",
    "\n",
    "        # Inverse scale (match your training/eval)\n",
    "        if scaler:\n",
    "            gt_arr = torch.tensor([gt], dtype=torch.float32).view(1, 1)\n",
    "            y_arr = torch.tensor([y_hat], dtype=torch.float32).view(1, 1)\n",
    "            gt = utils.inverse_transform_tensor(gt_arr, scaler).item() if hasattr(utils, \"inverse_transform_tensor\") else scaler.inverse_transform(gt_arr).item()\n",
    "            y_hat = utils.inverse_transform_tensor(y_arr, scaler).item() if hasattr(utils, \"inverse_transform_tensor\") else scaler.inverse_transform(y_arr).item()\n",
    "\n",
    "        gts.append(gt)\n",
    "        preds.append(y_hat)\n",
    "\n",
    "    return np.array(gts, dtype=np.float64), np.array(preds, dtype=np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ef77728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of valid edges: 5088\n",
      "\n",
      "=== GT Descriptive Statistics (raw) ===\n",
      "Min     : 191.405\n",
      "Max     : 113436.372\n",
      "Mean    : 25243.410\n",
      "Median  : 20618.627\n",
      "Std     : 18893.461\n",
      "======================================\n",
      "\n",
      "[PCA] Reduced from 20 → 20 dims; explained variance = 100.00%\n",
      "LSOA feature dim (preloaded): 20\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"param/projection/best_stage_1_lr1e-03.pt\"\n",
    "\n",
    "set_seeds(TRAINING['seed'])\n",
    "device = torch.device(TRAINING['device'])\n",
    "\n",
    "# Load GT and split\n",
    "edge_to_gt, scaler = load_gt()\n",
    "all_edge_ids = list(edge_to_gt.keys())\n",
    "\n",
    "# Load model\n",
    "model = load_model(checkpoint_path, device)\n",
    "\n",
    "# Inference\n",
    "gt, pred = infer_on_edges(model, all_edge_ids, edge_to_gt, scaler, device)\n",
    "\n",
    "# Save arrays\n",
    "out_dir = \"projection\"\n",
    "Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "ts = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9233cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 5088 entries to projection/prediction_2040.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def save_results_json(edge_ids, gt_arr, pred_arr, out_path):\n",
    "    out = []\n",
    "    for eid, gt, pred in zip(edge_ids, gt_arr, pred_arr):\n",
    "        out.append({\n",
    "            \"edge_id\": eid,\n",
    "            \"gt\": float(gt),\n",
    "            \"pred\": float(pred)\n",
    "        })\n",
    "    Path(out_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(out_path, \"w\") as f:\n",
    "        json.dump(out, f, indent=2)\n",
    "    print(f\"Saved {len(out)} entries to {out_path}\")\n",
    "\n",
    "save_results_json(\n",
    "    all_edge_ids,\n",
    "    gt,\n",
    "    pred,\n",
    "    f\"{out_dir}/prediction_{year}.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7e2816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
