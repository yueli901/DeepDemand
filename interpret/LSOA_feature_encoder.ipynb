{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aa28d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "# set the notebook's CWD to your repo root\n",
    "%cd D:/deepdemand\n",
    "ROOT = Path.cwd().parents[0]   # go up one level\n",
    "sys.path.insert(0, str(ROOT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8c0035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data] Raw LSOA feature matrix: (35672, 121)\n",
      "[PCA] Projected to shape (35672, 64) using saved model.\n",
      "[Emb] E_O: (35672, 16)   E_D: (35672, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yueli\\AppData\\Local\\Temp\\ipykernel_50200\\60083496.py:42: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Save] Wrote embeddings to:\n",
      "  - interpret/node_embeddings/E_O.npy\n",
      "  - interpret/node_embeddings/E_D.npy\n",
      "  - interpret/node_embeddings\\embeddings_O_D.csv\n"
     ]
    }
   ],
   "source": [
    "# === Extract O/D embeddings for all LSOAs from a trained DeepDemand checkpoint ===\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from config import MODEL  # uses MODEL['node_hidden'], ['node_out']\n",
    "from model.dataloader import load_json, get_lsoa_vector\n",
    "\n",
    "# -------------------\n",
    "# Config paths\n",
    "# -------------------\n",
    "CKPT_PATH   = \"param/cv_0/best_stage_1_lr1e-03.pt\"   # <- update if needed\n",
    "LSOA_JSON   = \"data/node_features/lsoa21_features_normalized.json\"\n",
    "PCA_MODEL   = \"data/node_features/pca_model_lsoa21.npz\"       # if you trained with PCA, this should exist\n",
    "OUT_DIR     = \"interpret/node_embeddings\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# -------------------\n",
    "# Minimal MLP def (must match training MLP)\n",
    "# -------------------\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dims, out_dim, dropout=0.1, act=nn.ReLU):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        d = in_dim\n",
    "        for h in hidden_dims:\n",
    "            layers += [nn.Linear(d, h), act(), nn.Dropout(dropout)]\n",
    "            d = h\n",
    "        layers += [nn.Linear(d, out_dim)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# -------------------\n",
    "# Helpers\n",
    "# -------------------\n",
    "def load_ckpt_state(ckpt_path):\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    return ckpt[\"state_dict\"] if isinstance(ckpt, dict) and \"state_dict\" in ckpt else ckpt\n",
    "\n",
    "def strip_and_load(mlp: nn.Module, full_sd: dict, prefix: str):\n",
    "    \"\"\"\n",
    "    Load weights into `mlp` by taking items that start with `prefix` (e.g., 'enc_O.')\n",
    "    and stripping that prefix so they match `mlp`'s keys (which start with 'net.').\n",
    "    \"\"\"\n",
    "    sub = {k[len(prefix):]: v for k, v in full_sd.items() if k.startswith(prefix)}\n",
    "    missing, unexpected = mlp.load_state_dict(sub, strict=False)\n",
    "    if missing:\n",
    "        print(f\"[WARN] Missing keys for {prefix}: {missing}\")\n",
    "    if unexpected:\n",
    "        print(f\"[WARN] Unexpected keys for {prefix}: {unexpected}\")\n",
    "\n",
    "def maybe_pca_project(X: np.ndarray, pca_npz_path: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    If PCA file exists, project X using saved mean/components.\n",
    "    Else return X unchanged.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(pca_npz_path):\n",
    "        print(\"[PCA] No PCA model found -> using raw features.\")\n",
    "        return X\n",
    "    npz = np.load(pca_npz_path, allow_pickle=True)\n",
    "    mean = npz[\"mean\"]           # (F,)\n",
    "    comps = npz[\"components\"]    # (k, F)\n",
    "    Xp = (X - mean) @ comps.T    # (N, k)\n",
    "    print(f\"[PCA] Projected to shape {Xp.shape} using saved model.\")\n",
    "    return Xp.astype(np.float32)\n",
    "\n",
    "# -------------------\n",
    "# 1) Build feature matrix X (N_lsoa, F_raw)\n",
    "# -------------------\n",
    "lsoa_json = load_json(LSOA_JSON)\n",
    "lsoa_codes = sorted(lsoa_json.keys())\n",
    "\n",
    "rows = []\n",
    "for code in lsoa_codes:\n",
    "    vec = get_lsoa_vector(lsoa_json[code])  # torch tensor (F_raw,)\n",
    "    rows.append(vec.cpu().numpy())\n",
    "X = np.vstack(rows).astype(np.float32)      # (N, F_raw)\n",
    "print(f\"[Data] Raw LSOA feature matrix: {X.shape}\")\n",
    "\n",
    "# Optional PCA (uses saved training PCA if present)\n",
    "X_in = maybe_pca_project(X, PCA_MODEL)\n",
    "in_dim = X_in.shape[1]\n",
    "\n",
    "# -------------------\n",
    "# 2) Instantiate encoders (same dims as training)\n",
    "# -------------------\n",
    "enc_O = MLP(in_dim, MODEL['node_hidden'], MODEL['node_out'], dropout=0.1)\n",
    "enc_D = MLP(in_dim, MODEL['node_hidden'], MODEL['node_out'], dropout=0.1)\n",
    "\n",
    "# Load only the encoder weights from checkpoint\n",
    "full_sd = load_ckpt_state(CKPT_PATH)\n",
    "strip_and_load(enc_O, full_sd, prefix=\"enc_O.\")\n",
    "strip_and_load(enc_D, full_sd, prefix=\"enc_D.\")\n",
    "\n",
    "enc_O.eval()\n",
    "enc_D.eval()\n",
    "\n",
    "# -------------------\n",
    "# 3) Forward pass to get embeddings\n",
    "# -------------------\n",
    "with torch.no_grad():\n",
    "    X_tensor = torch.from_numpy(X_in)              # (N, in_dim)\n",
    "    E_O = enc_O(X_tensor).cpu().numpy()           # (N, d_out)\n",
    "    E_D = enc_D(X_tensor).cpu().numpy()           # (N, d_out)\n",
    "\n",
    "print(f\"[Emb] E_O: {E_O.shape}   E_D: {E_D.shape}\")\n",
    "\n",
    "# -------------------\n",
    "# 4) Save outputs\n",
    "# -------------------\n",
    "# Numpy arrays\n",
    "np.save(os.path.join(OUT_DIR, \"E_O.npy\"), E_O)\n",
    "np.save(os.path.join(OUT_DIR, \"E_D.npy\"), E_D)\n",
    "np.save(os.path.join(OUT_DIR, \"LSOA_codes.npy\"), np.array(lsoa_codes, dtype=object))\n",
    "\n",
    "# Convenient table (first few dims for quick inspection)\n",
    "dout = E_O.shape[1]\n",
    "cols_O = [f\"eO_{i}\" for i in range(dout)]\n",
    "cols_D = [f\"eD_{i}\" for i in range(dout)]\n",
    "df = pd.DataFrame({\n",
    "    \"lsoa_code\": lsoa_codes,\n",
    "    **{c: E_O[:, i] for i, c in enumerate(cols_O)},\n",
    "    **{c: E_D[:, i] for i, c in enumerate(cols_D)},\n",
    "})\n",
    "out_csv = os.path.join(OUT_DIR, \"embeddings_O_D.csv\")\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(f\"[Save] Wrote embeddings to:\\n  - {OUT_DIR}/E_O.npy\\n  - {OUT_DIR}/E_D.npy\\n  - {out_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9864cb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yueli\\miniconda3\\envs\\pytorch_gpu\\lib\\site-packages\\umap\\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "c:\\Users\\yueli\\miniconda3\\envs\\pytorch_gpu\\lib\\site-packages\\umap\\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: node_embeddings/umap\\umap_O_Households with car ownership.pdf\n",
      "Saved: node_embeddings/umap\\umap_D_Households with car ownership.pdf\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Visualize O/D embeddings with UMAP, per-figure color scaling\n",
    "# and a flexible metric config extracted from the LSOA JSON.\n",
    "# Requirements: pip install umap-learn matplotlib numpy pandas\n",
    "\n",
    "import os, json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- Paths ----------\n",
    "EMB_DIR     = \"node_embeddings\"\n",
    "LSOA_JSON   = \"../data/node_features/lsoa21_features_raw.json\"\n",
    "OUT_DIR     = \"node_embeddings/umap\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ---------- Load embeddings ----------\n",
    "E_O = np.load(os.path.join(EMB_DIR, \"E_O.npy\"))          # (N, d)\n",
    "E_D = np.load(os.path.join(EMB_DIR, \"E_D.npy\"))          # (N, d)\n",
    "codes = np.load(os.path.join(EMB_DIR, \"LSOA_codes.npy\"), allow_pickle=True)  # (N,)\n",
    "\n",
    "# ---------- Load features JSON ----------\n",
    "with open(LSOA_JSON, \"r\") as f:\n",
    "    lsoa_json = json.load(f)\n",
    "\n",
    "# ---------- Metric config ----------\n",
    "# Each metric can be:\n",
    "#   {\"name\": ..., \"num\": (\"path\",\"to\",\"list_or_scalar\", idx_or_None),\n",
    "#                    \"den\": (\"path\",\"to\",\"list_or_scalar\", idx_or_None) or None,\n",
    "#                    \"transform\": \"log1p\"/None,\n",
    "#                    \"desc\": \"... (for filenames)\"}\n",
    "#\n",
    "# For list-like leaves provide an integer index; for scalars use None.\n",
    "# Example below matches your earlier usage (density = total / area).\n",
    "METRICS = [\n",
    "    {\n",
    "        \"name\": \"Households with car ownership\",\n",
    "        \"num\": (\"households\",\"lv3\",2),\n",
    "        \"den\": None, \n",
    "        \"transform\": None,\n",
    "        \"desc\": \"Households with car ownership\"\n",
    "    },\n",
    "]\n",
    "\n",
    "# ---------- Helpers to extract metrics ----------\n",
    "def _get_leaf(rec, path_tuple):\n",
    "    \"\"\"Fetch a value from nested dict/list: (\"key1\",\"key2\", index_or_None).\"\"\"\n",
    "    if path_tuple is None:\n",
    "        return np.nan\n",
    "    *keys, idx = path_tuple\n",
    "    cur = rec\n",
    "    for k in keys:\n",
    "        if not isinstance(cur, dict) or k not in cur:\n",
    "            return np.nan\n",
    "        cur = cur[k]\n",
    "    if idx is None:\n",
    "        # scalar leaf\n",
    "        try:\n",
    "            return float(cur)\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "    # list-like leaf\n",
    "    try:\n",
    "        return float(cur[idx])\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def compute_metric_vector(codes, metric_spec, lsoa_json):\n",
    "    vals = np.full(len(codes), np.nan, dtype=float)\n",
    "    for i, code in enumerate(codes):\n",
    "        rec = lsoa_json.get(str(code), {})\n",
    "        num = _get_leaf(rec, metric_spec[\"num\"])\n",
    "        den = _get_leaf(rec, metric_spec[\"den\"]) if metric_spec.get(\"den\") else 1.0\n",
    "        if den is None or den == 0:\n",
    "            vals[i] = np.nan\n",
    "        else:\n",
    "            vals[i] = num / den\n",
    "    if metric_spec.get(\"transform\") == \"log1p\":\n",
    "        vals = np.log1p(np.clip(vals, a_min=0, a_max=None))\n",
    "    return vals\n",
    "\n",
    "# ---------- Simple per-dim z-score before UMAP ----------\n",
    "def zscore(X, eps=1e-8):\n",
    "    mu = X.mean(axis=0, keepdims=True)\n",
    "    sd = X.std(axis=0, keepdims=True)\n",
    "    return (X - mu) / (sd + eps)\n",
    "\n",
    "E_O_std = zscore(E_O)\n",
    "E_D_std = zscore(E_D)\n",
    "\n",
    "# ---------- UMAP (same hyperparams for O/D) ----------\n",
    "reducer_params = dict(\n",
    "    n_components=2,\n",
    "    n_neighbors=30,\n",
    "    min_dist=0.1,\n",
    "    metric=\"euclidean\",\n",
    "    random_state=42,\n",
    ")\n",
    "U_O = umap.UMAP(**reducer_params).fit_transform(E_O_std)\n",
    "U_D = umap.UMAP(**reducer_params).fit_transform(E_D_std)\n",
    "\n",
    "# ---------- Plot helper with per-figure robust color scaling ----------\n",
    "def scatter_umap(U, color_vals, title, c_label, out_png):\n",
    "    vals = np.asarray(color_vals, dtype=float)\n",
    "    # mask NaNs\n",
    "    mask = ~np.isnan(vals)\n",
    "    if mask.sum() < 5:\n",
    "        print(f\"[WARN] Too few valid values for color in {title}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # robust per-figure scaling: 1st–99th percentiles\n",
    "    vmin = np.nanpercentile(vals, 1.0)\n",
    "    vmax = np.nanpercentile(vals, 99.0)\n",
    "    if not np.isfinite(vmin) or not np.isfinite(vmax) or vmin >= vmax:\n",
    "        vmin, vmax = np.nanmin(vals), np.nanmax(vals)\n",
    "\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sc = plt.scatter(U[mask, 0], U[mask, 1],\n",
    "                     c=vals[mask],\n",
    "                     s=3, alpha=0.25, edgecolor=\"none\",\n",
    "                     vmin=vmin, vmax=vmax, cmap=\"turbo\")\n",
    "    cbar = plt.colorbar(sc)\n",
    "    cbar.set_label(c_label)\n",
    "    cbar.solids.set_alpha(0.7)\n",
    "    # plt.title(title)\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png)\n",
    "    plt.close()\n",
    "    print(f\"Saved: {out_png}\")\n",
    "\n",
    "# ---------- Compute & plot all metrics automatically ----------\n",
    "records = []\n",
    "for spec in METRICS:\n",
    "    name = spec[\"name\"]\n",
    "    vals = compute_metric_vector(codes, spec, lsoa_json)\n",
    "\n",
    "    # Save numeric vectors for reference\n",
    "    np.save(os.path.join(OUT_DIR, f\"{name}_values.npy\"), vals)\n",
    "\n",
    "    # Plot O and D with *individual* per-figure scaling\n",
    "    scatter_umap(U_O, vals,\n",
    "                 title=f\"UMAP (O-encoder) — {name}\",\n",
    "                 c_label=spec.get(\"desc\", name),\n",
    "                 out_png=os.path.join(OUT_DIR, f\"umap_O_{name}.pdf\"))\n",
    "    scatter_umap(U_D, vals,\n",
    "                 title=f\"UMAP (D-encoder) — {name}\",\n",
    "                 c_label=spec.get(\"desc\", name),\n",
    "                 out_png=os.path.join(OUT_DIR, f\"umap_D_{name}.pdf\"))\n",
    "\n",
    "    # For downstream table joins\n",
    "    records.append(pd.DataFrame({\n",
    "        \"lsoa_code\": codes,\n",
    "        f\"{name}\": vals\n",
    "    }))\n",
    "\n",
    "# ---------- Save UMAP coords and a merged CSV ----------\n",
    "np.save(os.path.join(OUT_DIR, \"U_O.npy\"), U_O)\n",
    "np.save(os.path.join(OUT_DIR, \"U_D.npy\"), U_D)\n",
    "\n",
    "# Build two CSVs (O/D) with coords + all metrics\n",
    "df_metrics = records[0]\n",
    "for df in records[1:]:\n",
    "    df_metrics = df_metrics.merge(df, on=\"lsoa_code\", how=\"outer\")\n",
    "\n",
    "df_O = pd.DataFrame({\"lsoa_code\": codes, \"umap_x\": U_O[:,0], \"umap_y\": U_O[:,1]}).merge(df_metrics, on=\"lsoa_code\", how=\"left\")\n",
    "df_D = pd.DataFrame({\"lsoa_code\": codes, \"umap_x\": U_D[:,0], \"umap_y\": U_D[:,1]}).merge(df_metrics, on=\"lsoa_code\", how=\"left\")\n",
    "\n",
    "df_O.to_csv(os.path.join(OUT_DIR, \"umap_O_all_metrics.csv\"), index=False)\n",
    "df_D.to_csv(os.path.join(OUT_DIR, \"umap_D_all_metrics.csv\"), index=False)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "265dddf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: node_embeddings/umap\\umap_O_colored_by_O_score.pdf\n",
      "Saved: node_embeddings/umap\\umap_D_colored_by_D_score.pdf\n",
      "Done: saved 2 SVGs recolored by O/D scores.\n"
     ]
    }
   ],
   "source": [
    "# --- UMAP recolor by O/D potential (O_score / D_score) ---\n",
    "# Assumes these already exist in memory from your previous script:\n",
    "#   - U_O, U_D (Nx2)\n",
    "#   - codes (N,)\n",
    "#   - OUT_DIR (string path)\n",
    "# Also reuses scatter_umap() from your previous script (same styling + robust scaling).\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "OD_CSV = \"OD_scores/O_D_scores.csv\"\n",
    "OUT_DIR = \"node_embeddings/umap\"\n",
    "\n",
    "# ---- load O/D scores ----\n",
    "df_od = pd.read_csv(OD_CSV, dtype={\"lsoa_code\": str})\n",
    "df_od[\"lsoa_code\"] = df_od[\"lsoa_code\"].astype(str).str.strip()\n",
    "\n",
    "# map for fast lookup\n",
    "o_map = dict(zip(df_od[\"lsoa_code\"].values, df_od[\"O_score\"].astype(float).values))\n",
    "d_map = dict(zip(df_od[\"lsoa_code\"].values, df_od[\"D_score\"].astype(float).values))\n",
    "\n",
    "# build vectors aligned to `codes`\n",
    "codes_str = np.asarray(codes, dtype=str)\n",
    "o_vals = np.array([o_map.get(c, np.nan) for c in codes_str], dtype=float)\n",
    "d_vals = np.array([d_map.get(c, np.nan) for c in codes_str], dtype=float)\n",
    "\n",
    "# optional: save vectors\n",
    "np.save(os.path.join(OUT_DIR, \"O_score_values.npy\"), o_vals)\n",
    "np.save(os.path.join(OUT_DIR, \"D_score_values.npy\"), d_vals)\n",
    "\n",
    "# ---- plot: O-embedding colored by O_score; D-embedding colored by D_score ----\n",
    "scatter_umap(\n",
    "    U_O, o_vals,\n",
    "    title=\"UMAP (O-encoder) — O potential\",\n",
    "    c_label=\"O potential (O score)\",\n",
    "    out_png=os.path.join(OUT_DIR, \"umap_O_colored_by_O_score.pdf\")\n",
    ")\n",
    "\n",
    "scatter_umap(\n",
    "    U_D, d_vals,\n",
    "    title=\"UMAP (D-encoder) — D potential\",\n",
    "    c_label=\"O/D potential\",\n",
    "    out_png=os.path.join(OUT_DIR, \"umap_D_colored_by_D_score.pdf\")\n",
    ")\n",
    "\n",
    "print(\"Done: saved 2 SVGs recolored by O/D scores.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb821067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
